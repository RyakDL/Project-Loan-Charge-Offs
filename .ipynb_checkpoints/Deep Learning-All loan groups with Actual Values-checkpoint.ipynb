{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b492e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "764d6b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'observation_date', 'C&I_DELNQ', 'CCARD_CO',\n",
       "       'CCARD_DELNQ', 'CORP_DEBT_NET_WORTH', 'CORP_SAVINGS_LEVEL', 'CRE_CO',\n",
       "       'CRE_DELNQ', 'GDP', 'Homeowner_Vacancy_rate', 'Household_DBT_Inc',\n",
       "       'Mortgage_CO', 'Mortgage_DELNQ', 'Rental_Vacancy_Rate',\n",
       "       'Consumer_Confidence', 'FEDFUNDS', 'Manufacturing_Confidence',\n",
       "       'SAVINGS_RATE_MO', 'UNRATE', 'C&I_CO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DataFrame \n",
    "main_df = pd.read_csv('Rates_MO.csv')\n",
    "main_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33b87d",
   "metadata": {},
   "source": [
    "# Credit Cards Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc6061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create credit card dataset\n",
    "ccard_df = main_df[['observation_date', 'CCARD_CO', 'CCARD_DELNQ', 'GDP', 'Household_DBT_Inc', 'Consumer_Confidence', 'FEDFUNDS', 'SAVINGS_RATE_MO', 'UNRATE']]\n",
    " \n",
    "# Create copy for bins\n",
    "ccard_bin_df = ccard_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7424394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning the data for classification Question: \n",
    "ccard_bin_df[\"CCARD_CO_BIN\"] = pd.qcut(ccard_df['CCARD_CO'],4, labels= [1, 2, 3, 4])\n",
    "\n",
    "# Seperate the y and X variables\n",
    "y = ccard_bin_df[\"CCARD_CO_BIN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "021509da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCARD_DELNQ</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Household_DBT_Inc</th>\n",
       "      <th>Consumer_Confidence</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>SAVINGS_RATE_MO</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.26</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>66.8</td>\n",
       "      <td>6.91</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.26</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>70.4</td>\n",
       "      <td>6.25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.26</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>87.7</td>\n",
       "      <td>6.12</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.48</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.434237</td>\n",
       "      <td>81.8</td>\n",
       "      <td>5.91</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.48</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.434237</td>\n",
       "      <td>78.3</td>\n",
       "      <td>5.78</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2.43</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.848832</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2.43</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.848832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2.77</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>63.5</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2.77</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>59.2</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2.77</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>64.4</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CCARD_DELNQ  GDP  Household_DBT_Inc  Consumer_Confidence  FEDFUNDS  \\\n",
       "0           5.26 -1.9          11.578032                 66.8      6.91   \n",
       "1           5.26 -1.9          11.578032                 70.4      6.25   \n",
       "2           5.26 -1.9          11.578032                 87.7      6.12   \n",
       "3           5.48  3.2          11.434237                 81.8      5.91   \n",
       "4           5.48  3.2          11.434237                 78.3      5.78   \n",
       "..           ...  ...                ...                  ...       ...   \n",
       "385         2.43  2.2           9.848832                 67.0      4.57   \n",
       "386         2.43  2.2           9.848832                 62.0      4.65   \n",
       "387         2.77  2.1           9.826692                 63.5      4.83   \n",
       "388         2.77  2.1           9.826692                 59.2      5.06   \n",
       "389         2.77  2.1           9.826692                 64.4      5.08   \n",
       "\n",
       "     SAVINGS_RATE_MO  UNRATE  \n",
       "0                9.4     6.4  \n",
       "1                9.0     6.6  \n",
       "2                8.1     6.8  \n",
       "3                8.7     6.7  \n",
       "4                8.5     6.9  \n",
       "..               ...     ...  \n",
       "385              4.7     3.6  \n",
       "386              5.2     3.5  \n",
       "387              5.2     3.4  \n",
       "388              5.3     3.7  \n",
       "389              4.9     3.6  \n",
       "\n",
       "[390 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccard_df = ccard_df.drop(columns=[\"CCARD_CO\",\"observation_date\"])\n",
    "ccard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c4f8d",
   "metadata": {},
   "source": [
    "# Deep Learning - Credit Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0dcb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ccard_df, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4033bb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75ac2a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16858238 0.48089172 0.31664056 ... 0.65889213 0.10784314 0.01769912]\n",
      " [0.5210728  0.55414013 0.60881321 ... 0.75364431 0.13398693 0.19469027]\n",
      " [0.58429119 0.45700637 0.43389017 ... 0.44023324 0.24183007 0.31858407]\n",
      " ...\n",
      " [0.57471264 0.55254777 0.66558862 ... 0.75072886 0.08496732 0.0619469 ]\n",
      " [0.33333333 0.53343949 0.44074702 ... 0.57725948 0.19934641 0.23893805]\n",
      " [0.47318008 0.48566879 0.95252878 ... 0.75801749 0.04248366 0.10619469]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d881bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set shape:  (292, 7)\n",
      "y_train set shape:  (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train set shape: \", X_train_scaled.shape)\n",
    "print(\"y_train set shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5d5892e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 2, 1, ..., 2, 1, 3, 1, 2]\n",
       "Length: 292\n",
       "Categories (4, int64): [1 < 2 < 3 < 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09f18238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = to_categorical(y_train.values, num_classes)\n",
    "y_test = to_categorical(y_test.values, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "939bab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 205       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11385 (44.47 KB)\n",
      "Trainable params: 11385 (44.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layers1 = 60\n",
    "hidden_nodes_layers2 = 60\n",
    "hidden_nodes_layers3 = 60\n",
    "hidden_nodes_layers4 = 40\n",
    "\n",
    "\n",
    "model.add(Dense(20, activation='relu', input_dim=number_input_features))\n",
    "model.add(Dense(hidden_nodes_layers1, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers2, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers3, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers4, activation='relu'))\n",
    "# model.add(Dense(hidden_nodes_layers5, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e1aad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 1.5729 - accuracy: 0.2500 - 148ms/epoch - 15ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 1.5103 - accuracy: 0.2568 - 5ms/epoch - 516us/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 1.4511 - accuracy: 0.2671 - 5ms/epoch - 496us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.3984 - accuracy: 0.2774 - 5ms/epoch - 483us/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.3343 - accuracy: 0.3699 - 5ms/epoch - 457us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 1.2676 - accuracy: 0.5274 - 5ms/epoch - 454us/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 1.1801 - accuracy: 0.5890 - 5ms/epoch - 451us/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 1.1054 - accuracy: 0.5582 - 5ms/epoch - 471us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 1.0265 - accuracy: 0.5548 - 5ms/epoch - 515us/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.9482 - accuracy: 0.6062 - 5ms/epoch - 514us/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.9076 - accuracy: 0.5856 - 5ms/epoch - 535us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.8533 - accuracy: 0.6541 - 6ms/epoch - 555us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.8488 - accuracy: 0.6336 - 5ms/epoch - 524us/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.8307 - accuracy: 0.6541 - 6ms/epoch - 557us/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.8035 - accuracy: 0.6507 - 5ms/epoch - 537us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.7486 - accuracy: 0.6610 - 5ms/epoch - 540us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.7160 - accuracy: 0.6884 - 6ms/epoch - 578us/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.6794 - accuracy: 0.7295 - 5ms/epoch - 545us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.6670 - accuracy: 0.6952 - 5ms/epoch - 513us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.6374 - accuracy: 0.7500 - 6ms/epoch - 584us/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.6309 - accuracy: 0.7534 - 5ms/epoch - 541us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.5813 - accuracy: 0.7534 - 5ms/epoch - 524us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.6450 - accuracy: 0.7500 - 6ms/epoch - 575us/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.6281 - accuracy: 0.7192 - 5ms/epoch - 535us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.5432 - accuracy: 0.8048 - 5ms/epoch - 546us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.5169 - accuracy: 0.8014 - 5ms/epoch - 550us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.5037 - accuracy: 0.7945 - 5ms/epoch - 535us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.5012 - accuracy: 0.7979 - 5ms/epoch - 546us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.4777 - accuracy: 0.7979 - 6ms/epoch - 555us/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.4858 - accuracy: 0.8116 - 5ms/epoch - 544us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.4675 - accuracy: 0.8253 - 5ms/epoch - 534us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.4507 - accuracy: 0.8082 - 5ms/epoch - 542us/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.4324 - accuracy: 0.8288 - 5ms/epoch - 525us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.4420 - accuracy: 0.8219 - 6ms/epoch - 574us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.4759 - accuracy: 0.7945 - 5ms/epoch - 521us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.4776 - accuracy: 0.7945 - 6ms/epoch - 560us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.4038 - accuracy: 0.8253 - 5ms/epoch - 550us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.3870 - accuracy: 0.8322 - 5ms/epoch - 521us/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.4197 - accuracy: 0.8356 - 6ms/epoch - 556us/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.3522 - accuracy: 0.8664 - 6ms/epoch - 561us/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.4134 - accuracy: 0.8219 - 5ms/epoch - 534us/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.4103 - accuracy: 0.8356 - 6ms/epoch - 569us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.3688 - accuracy: 0.8527 - 6ms/epoch - 578us/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.3373 - accuracy: 0.8767 - 6ms/epoch - 564us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.3255 - accuracy: 0.8596 - 6ms/epoch - 555us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.3255 - accuracy: 0.8801 - 5ms/epoch - 525us/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.4005 - accuracy: 0.8288 - 6ms/epoch - 576us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.3233 - accuracy: 0.8630 - 6ms/epoch - 558us/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.3408 - accuracy: 0.8527 - 5ms/epoch - 535us/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.3112 - accuracy: 0.8801 - 6ms/epoch - 554us/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.3003 - accuracy: 0.8904 - 5ms/epoch - 549us/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.2972 - accuracy: 0.8973 - 5ms/epoch - 525us/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.2874 - accuracy: 0.8870 - 6ms/epoch - 578us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.3017 - accuracy: 0.8904 - 5ms/epoch - 522us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.2799 - accuracy: 0.8904 - 5ms/epoch - 545us/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.2878 - accuracy: 0.8836 - 5ms/epoch - 522us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.2650 - accuracy: 0.9075 - 5ms/epoch - 524us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.2594 - accuracy: 0.9041 - 5ms/epoch - 542us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.2796 - accuracy: 0.8870 - 5ms/epoch - 527us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.2677 - accuracy: 0.9075 - 5ms/epoch - 521us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.2664 - accuracy: 0.9007 - 5ms/epoch - 542us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.3221 - accuracy: 0.8664 - 5ms/epoch - 523us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.2855 - accuracy: 0.9007 - 5ms/epoch - 509us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.2684 - accuracy: 0.8801 - 5ms/epoch - 527us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.2565 - accuracy: 0.8973 - 5ms/epoch - 527us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.2432 - accuracy: 0.9075 - 5ms/epoch - 521us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.2589 - accuracy: 0.9110 - 5ms/epoch - 514us/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.2512 - accuracy: 0.9247 - 5ms/epoch - 534us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.2653 - accuracy: 0.8767 - 5ms/epoch - 536us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.2595 - accuracy: 0.8904 - 6ms/epoch - 579us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.2698 - accuracy: 0.9007 - 5ms/epoch - 508us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.2761 - accuracy: 0.8733 - 5ms/epoch - 532us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.2197 - accuracy: 0.9247 - 5ms/epoch - 524us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.2271 - accuracy: 0.9178 - 5ms/epoch - 530us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.2220 - accuracy: 0.9247 - 5ms/epoch - 544us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.2250 - accuracy: 0.9041 - 6ms/epoch - 551us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.2229 - accuracy: 0.9178 - 5ms/epoch - 512us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.2198 - accuracy: 0.9315 - 5ms/epoch - 529us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.2409 - accuracy: 0.9075 - 5ms/epoch - 515us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.2211 - accuracy: 0.9144 - 5ms/epoch - 516us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.2208 - accuracy: 0.9384 - 5ms/epoch - 544us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.2509 - accuracy: 0.8870 - 5ms/epoch - 516us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.2508 - accuracy: 0.9110 - 5ms/epoch - 531us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.2574 - accuracy: 0.8973 - 5ms/epoch - 543us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.2180 - accuracy: 0.9281 - 5ms/epoch - 524us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.2200 - accuracy: 0.9110 - 5ms/epoch - 533us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.1983 - accuracy: 0.9349 - 5ms/epoch - 521us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.2411 - accuracy: 0.9007 - 5ms/epoch - 525us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.2101 - accuracy: 0.9247 - 5ms/epoch - 512us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.2363 - accuracy: 0.9110 - 5ms/epoch - 539us/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.2363 - accuracy: 0.9178 - 5ms/epoch - 523us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.2299 - accuracy: 0.9007 - 6ms/epoch - 559us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.2823 - accuracy: 0.8801 - 5ms/epoch - 530us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.2399 - accuracy: 0.8938 - 5ms/epoch - 534us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.2110 - accuracy: 0.9281 - 6ms/epoch - 553us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.2247 - accuracy: 0.9247 - 5ms/epoch - 524us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.2349 - accuracy: 0.8767 - 5ms/epoch - 518us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.2444 - accuracy: 0.9075 - 6ms/epoch - 559us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.2179 - accuracy: 0.9144 - 5ms/epoch - 537us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.1983 - accuracy: 0.9384 - 5ms/epoch - 523us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.1820 - accuracy: 0.9418 - 5ms/epoch - 532us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.1874 - accuracy: 0.9349 - 5ms/epoch - 504us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.1785 - accuracy: 0.9555 - 5ms/epoch - 545us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.1949 - accuracy: 0.9384 - 5ms/epoch - 515us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.1872 - accuracy: 0.9281 - 5ms/epoch - 524us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.2127 - accuracy: 0.8973 - 5ms/epoch - 542us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.1808 - accuracy: 0.9452 - 5ms/epoch - 497us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.1700 - accuracy: 0.9521 - 5ms/epoch - 515us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.1799 - accuracy: 0.9349 - 6ms/epoch - 553us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.1685 - accuracy: 0.9521 - 5ms/epoch - 509us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.2029 - accuracy: 0.9144 - 5ms/epoch - 503us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.1935 - accuracy: 0.9349 - 5ms/epoch - 525us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.1854 - accuracy: 0.9281 - 5ms/epoch - 531us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.2068 - accuracy: 0.9110 - 5ms/epoch - 497us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.1895 - accuracy: 0.9418 - 5ms/epoch - 521us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.1602 - accuracy: 0.9418 - 5ms/epoch - 494us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.1673 - accuracy: 0.9349 - 5ms/epoch - 498us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.1693 - accuracy: 0.9452 - 5ms/epoch - 520us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.1667 - accuracy: 0.9384 - 5ms/epoch - 527us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.2061 - accuracy: 0.9110 - 5ms/epoch - 483us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.2479 - accuracy: 0.9144 - 5ms/epoch - 501us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.2389 - accuracy: 0.8904 - 5ms/epoch - 506us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.2149 - accuracy: 0.9075 - 5ms/epoch - 493us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.1744 - accuracy: 0.9418 - 5ms/epoch - 527us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.1968 - accuracy: 0.9247 - 5ms/epoch - 512us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.1655 - accuracy: 0.9418 - 5ms/epoch - 548us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.1611 - accuracy: 0.9521 - 5ms/epoch - 504us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.1602 - accuracy: 0.9486 - 5ms/epoch - 509us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.1609 - accuracy: 0.9384 - 5ms/epoch - 505us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.1511 - accuracy: 0.9589 - 5ms/epoch - 526us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.1641 - accuracy: 0.9418 - 5ms/epoch - 525us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.1808 - accuracy: 0.9144 - 5ms/epoch - 525us/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.1795 - accuracy: 0.9384 - 6ms/epoch - 560us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.1671 - accuracy: 0.9349 - 5ms/epoch - 517us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.1525 - accuracy: 0.9555 - 5ms/epoch - 523us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.1620 - accuracy: 0.9315 - 5ms/epoch - 525us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.1757 - accuracy: 0.9281 - 5ms/epoch - 541us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.1616 - accuracy: 0.9486 - 6ms/epoch - 557us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.2046 - accuracy: 0.9178 - 5ms/epoch - 459us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.2096 - accuracy: 0.9075 - 5ms/epoch - 499us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.1572 - accuracy: 0.9452 - 16ms/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.1527 - accuracy: 0.9349 - 6ms/epoch - 566us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.1495 - accuracy: 0.9486 - 5ms/epoch - 537us/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.1546 - accuracy: 0.9555 - 5ms/epoch - 531us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.1542 - accuracy: 0.9452 - 5ms/epoch - 529us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.1453 - accuracy: 0.9452 - 5ms/epoch - 529us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.1530 - accuracy: 0.9384 - 5ms/epoch - 544us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.1458 - accuracy: 0.9521 - 5ms/epoch - 529us/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.1841 - accuracy: 0.9247 - 5ms/epoch - 535us/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.1783 - accuracy: 0.9384 - 5ms/epoch - 549us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.1542 - accuracy: 0.9418 - 5ms/epoch - 523us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.1503 - accuracy: 0.9521 - 5ms/epoch - 515us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.2189 - accuracy: 0.9144 - 6ms/epoch - 570us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.2364 - accuracy: 0.9247 - 5ms/epoch - 509us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.4233 - accuracy: 0.8253 - 5ms/epoch - 518us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.2017 - accuracy: 0.9110 - 5ms/epoch - 545us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.1631 - accuracy: 0.9315 - 5ms/epoch - 521us/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.1577 - accuracy: 0.9418 - 5ms/epoch - 523us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.1467 - accuracy: 0.9521 - 5ms/epoch - 535us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.1359 - accuracy: 0.9623 - 5ms/epoch - 515us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.1348 - accuracy: 0.9555 - 5ms/epoch - 529us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.1300 - accuracy: 0.9623 - 5ms/epoch - 529us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.1340 - accuracy: 0.9623 - 5ms/epoch - 516us/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.1361 - accuracy: 0.9555 - 5ms/epoch - 536us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.1739 - accuracy: 0.9281 - 5ms/epoch - 514us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.1528 - accuracy: 0.9349 - 5ms/epoch - 509us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.1442 - accuracy: 0.9418 - 5ms/epoch - 538us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.1563 - accuracy: 0.9349 - 5ms/epoch - 511us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.1528 - accuracy: 0.9349 - 5ms/epoch - 501us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.1522 - accuracy: 0.9452 - 6ms/epoch - 600us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.1439 - accuracy: 0.9452 - 5ms/epoch - 538us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.1531 - accuracy: 0.9418 - 5ms/epoch - 517us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.1306 - accuracy: 0.9521 - 5ms/epoch - 541us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.1669 - accuracy: 0.9418 - 5ms/epoch - 517us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.1739 - accuracy: 0.9178 - 5ms/epoch - 542us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.1508 - accuracy: 0.9247 - 5ms/epoch - 526us/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.1322 - accuracy: 0.9452 - 5ms/epoch - 511us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.1321 - accuracy: 0.9452 - 6ms/epoch - 567us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.1449 - accuracy: 0.9486 - 5ms/epoch - 526us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.1497 - accuracy: 0.9349 - 5ms/epoch - 515us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.1627 - accuracy: 0.9384 - 5ms/epoch - 546us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.1336 - accuracy: 0.9555 - 5ms/epoch - 537us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.1464 - accuracy: 0.9315 - 5ms/epoch - 518us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.1406 - accuracy: 0.9418 - 5ms/epoch - 539us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.1631 - accuracy: 0.9418 - 5ms/epoch - 530us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.2063 - accuracy: 0.9144 - 5ms/epoch - 519us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.1651 - accuracy: 0.9315 - 6ms/epoch - 572us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.1360 - accuracy: 0.9452 - 5ms/epoch - 521us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.1489 - accuracy: 0.9384 - 5ms/epoch - 533us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.1451 - accuracy: 0.9418 - 5ms/epoch - 533us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.1258 - accuracy: 0.9555 - 5ms/epoch - 517us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.1485 - accuracy: 0.9247 - 5ms/epoch - 544us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.1322 - accuracy: 0.9521 - 5ms/epoch - 533us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.1745 - accuracy: 0.9349 - 5ms/epoch - 518us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.1244 - accuracy: 0.9555 - 5ms/epoch - 537us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.1205 - accuracy: 0.9555 - 5ms/epoch - 508us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.1206 - accuracy: 0.9589 - 5ms/epoch - 515us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.1257 - accuracy: 0.9521 - 5ms/epoch - 527us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.1141 - accuracy: 0.9623 - 5ms/epoch - 529us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.1165 - accuracy: 0.9555 - 5ms/epoch - 535us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1665fd450>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "335f4ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2710 - accuracy: 0.9286 - 66ms/epoch - 16ms/step\n",
      "Loss: 0.27099740505218506, Accuracy: 0.9285714030265808\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eeec33",
   "metadata": {},
   "source": [
    "# Mortgage Loan Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4317358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observation_date', 'Mortgage_CO', 'Mortgage_DELNQ', 'GDP',\n",
       "       'Household_DBT_Inc', 'Consumer_Confidence', 'FEDFUNDS',\n",
       "       'SAVINGS_RATE_MO', 'UNRATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mortgage loan dataset\n",
    "mort_df = main_df[['observation_date', 'Mortgage_CO', 'Mortgage_DELNQ', 'GDP', 'Household_DBT_Inc', 'Consumer_Confidence', 'FEDFUNDS', 'SAVINGS_RATE_MO', 'UNRATE']]\n",
    "\n",
    "mort_bin_df = mort_df.copy()\n",
    "\n",
    "mort_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1787ee06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mortgage_DELNQ</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Household_DBT_Inc</th>\n",
       "      <th>Consumer_Confidence</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>SAVINGS_RATE_MO</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.09</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>66.8</td>\n",
       "      <td>6.91</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.09</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>70.4</td>\n",
       "      <td>6.25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.09</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>87.7</td>\n",
       "      <td>6.12</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.18</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.434237</td>\n",
       "      <td>81.8</td>\n",
       "      <td>5.91</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.18</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.434237</td>\n",
       "      <td>78.3</td>\n",
       "      <td>5.78</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1.74</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.848832</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1.74</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.848832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1.72</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>63.5</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1.72</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>59.2</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1.72</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>64.4</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mortgage_DELNQ  GDP  Household_DBT_Inc  Consumer_Confidence  FEDFUNDS  \\\n",
       "0              3.09 -1.9          11.578032                 66.8      6.91   \n",
       "1              3.09 -1.9          11.578032                 70.4      6.25   \n",
       "2              3.09 -1.9          11.578032                 87.7      6.12   \n",
       "3              3.18  3.2          11.434237                 81.8      5.91   \n",
       "4              3.18  3.2          11.434237                 78.3      5.78   \n",
       "..              ...  ...                ...                  ...       ...   \n",
       "385            1.74  2.2           9.848832                 67.0      4.57   \n",
       "386            1.74  2.2           9.848832                 62.0      4.65   \n",
       "387            1.72  2.1           9.826692                 63.5      4.83   \n",
       "388            1.72  2.1           9.826692                 59.2      5.06   \n",
       "389            1.72  2.1           9.826692                 64.4      5.08   \n",
       "\n",
       "     SAVINGS_RATE_MO  UNRATE  \n",
       "0                9.4     6.4  \n",
       "1                9.0     6.6  \n",
       "2                8.1     6.8  \n",
       "3                8.7     6.7  \n",
       "4                8.5     6.9  \n",
       "..               ...     ...  \n",
       "385              4.7     3.6  \n",
       "386              5.2     3.5  \n",
       "387              5.2     3.4  \n",
       "388              5.3     3.7  \n",
       "389              4.9     3.6  \n",
       "\n",
       "[390 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binning the data for classification Question: \n",
    "mort_bin_df[\"Mortgage_CO_BIN\"] = pd.qcut(mort_df['Mortgage_CO'],4, labels= [1, 2, 3, 4])\n",
    "# Define the dependent Y variable\n",
    "y = mort_bin_df[\"Mortgage_CO_BIN\"]\n",
    "mort_df = mort_df.drop(columns=['Mortgage_CO','observation_date'])\n",
    "mort_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b2282",
   "metadata": {},
   "source": [
    "# Deep Learning: Mortgage Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b1a82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ccard_df, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aa98fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03b8158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set shape:  (292, 7)\n",
      "y_train set shape:  (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train set shape: \", X_train_scaled.shape)\n",
    "print(\"y_train set shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74552de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 3, 4, ..., 2, 1, 2, 3, 3]\n",
       "Length: 292\n",
       "Categories (4, int64): [1 < 2 < 3 < 4]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c8e2ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = to_categorical(y_train.values, num_classes)\n",
    "y_test = to_categorical(y_test.values, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ae91dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 205       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11385 (44.47 KB)\n",
      "Trainable params: 11385 (44.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layers1 = 60\n",
    "hidden_nodes_layers2 = 60\n",
    "hidden_nodes_layers3 = 60\n",
    "hidden_nodes_layers4 = 40\n",
    "\n",
    "\n",
    "model.add(Dense(20, activation='relu', input_dim=number_input_features))\n",
    "model.add(Dense(hidden_nodes_layers1, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers2, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers3, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers4, activation='relu'))\n",
    "# model.add(Dense(hidden_nodes_layers5, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f299af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 1.5992 - accuracy: 0.2295 - 128ms/epoch - 13ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 1.5598 - accuracy: 0.2774 - 5ms/epoch - 516us/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 1.5133 - accuracy: 0.3356 - 5ms/epoch - 503us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.4506 - accuracy: 0.4144 - 5ms/epoch - 496us/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.3754 - accuracy: 0.4212 - 4ms/epoch - 423us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 1.3083 - accuracy: 0.4726 - 5ms/epoch - 457us/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 1.2272 - accuracy: 0.5034 - 4ms/epoch - 431us/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 1.1939 - accuracy: 0.5240 - 5ms/epoch - 510us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 1.1223 - accuracy: 0.5753 - 5ms/epoch - 491us/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 1.0883 - accuracy: 0.5685 - 5ms/epoch - 522us/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 1.0548 - accuracy: 0.6199 - 5ms/epoch - 544us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.9922 - accuracy: 0.6370 - 5ms/epoch - 542us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.9567 - accuracy: 0.6336 - 6ms/epoch - 569us/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.9165 - accuracy: 0.6849 - 6ms/epoch - 582us/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.8710 - accuracy: 0.6781 - 5ms/epoch - 509us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.8317 - accuracy: 0.7055 - 5ms/epoch - 514us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.8104 - accuracy: 0.6884 - 6ms/epoch - 555us/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.7788 - accuracy: 0.7123 - 5ms/epoch - 529us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.7696 - accuracy: 0.7021 - 5ms/epoch - 543us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.7269 - accuracy: 0.7055 - 5ms/epoch - 545us/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.7229 - accuracy: 0.7089 - 6ms/epoch - 550us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.7311 - accuracy: 0.6986 - 5ms/epoch - 510us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.7145 - accuracy: 0.6849 - 5ms/epoch - 513us/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.6833 - accuracy: 0.7089 - 6ms/epoch - 579us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.6524 - accuracy: 0.7295 - 6ms/epoch - 552us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.6584 - accuracy: 0.7226 - 5ms/epoch - 534us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.6341 - accuracy: 0.7260 - 5ms/epoch - 542us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.6186 - accuracy: 0.7329 - 5ms/epoch - 539us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.6525 - accuracy: 0.6918 - 5ms/epoch - 521us/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.6395 - accuracy: 0.7192 - 5ms/epoch - 547us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.5988 - accuracy: 0.7397 - 5ms/epoch - 527us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.6100 - accuracy: 0.6986 - 5ms/epoch - 536us/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.5765 - accuracy: 0.7295 - 5ms/epoch - 535us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.5664 - accuracy: 0.7295 - 5ms/epoch - 524us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.5491 - accuracy: 0.7705 - 6ms/epoch - 576us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.5400 - accuracy: 0.7671 - 5ms/epoch - 520us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.5498 - accuracy: 0.7603 - 5ms/epoch - 528us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.5236 - accuracy: 0.7842 - 6ms/epoch - 576us/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.5427 - accuracy: 0.7774 - 5ms/epoch - 529us/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.5607 - accuracy: 0.7534 - 5ms/epoch - 531us/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.5228 - accuracy: 0.7774 - 6ms/epoch - 568us/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.5007 - accuracy: 0.7842 - 5ms/epoch - 535us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.4899 - accuracy: 0.8048 - 5ms/epoch - 513us/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.5095 - accuracy: 0.7740 - 6ms/epoch - 578us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.4831 - accuracy: 0.7911 - 5ms/epoch - 515us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.4741 - accuracy: 0.8116 - 5ms/epoch - 533us/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.4965 - accuracy: 0.7877 - 5ms/epoch - 521us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.4688 - accuracy: 0.7945 - 5ms/epoch - 519us/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.5133 - accuracy: 0.7877 - 6ms/epoch - 559us/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.4652 - accuracy: 0.7945 - 5ms/epoch - 537us/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.5145 - accuracy: 0.7466 - 5ms/epoch - 514us/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.4763 - accuracy: 0.7945 - 6ms/epoch - 576us/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.4580 - accuracy: 0.8151 - 5ms/epoch - 525us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.4992 - accuracy: 0.7808 - 5ms/epoch - 522us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.5591 - accuracy: 0.7603 - 5ms/epoch - 520us/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.4948 - accuracy: 0.7842 - 5ms/epoch - 544us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.4404 - accuracy: 0.8288 - 5ms/epoch - 550us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.4145 - accuracy: 0.8459 - 5ms/epoch - 524us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.4066 - accuracy: 0.8390 - 5ms/epoch - 518us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.4135 - accuracy: 0.8390 - 5ms/epoch - 531us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.4027 - accuracy: 0.8390 - 5ms/epoch - 501us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.4355 - accuracy: 0.8219 - 5ms/epoch - 514us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.3868 - accuracy: 0.8459 - 5ms/epoch - 539us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.3842 - accuracy: 0.8493 - 5ms/epoch - 523us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.3838 - accuracy: 0.8459 - 5ms/epoch - 533us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.3724 - accuracy: 0.8459 - 5ms/epoch - 530us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.3777 - accuracy: 0.8562 - 5ms/epoch - 527us/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.3592 - accuracy: 0.8493 - 5ms/epoch - 504us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.3592 - accuracy: 0.8493 - 5ms/epoch - 532us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.3994 - accuracy: 0.8356 - 5ms/epoch - 511us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.4032 - accuracy: 0.8390 - 5ms/epoch - 512us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.3482 - accuracy: 0.8459 - 5ms/epoch - 548us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.3572 - accuracy: 0.8630 - 5ms/epoch - 500us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.4299 - accuracy: 0.8185 - 6ms/epoch - 560us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.3623 - accuracy: 0.8527 - 6ms/epoch - 615us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.3361 - accuracy: 0.8733 - 5ms/epoch - 489us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.3424 - accuracy: 0.8390 - 5ms/epoch - 482us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.3303 - accuracy: 0.8767 - 7ms/epoch - 699us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.3368 - accuracy: 0.8801 - 5ms/epoch - 549us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.3491 - accuracy: 0.8664 - 5ms/epoch - 537us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.3265 - accuracy: 0.8596 - 5ms/epoch - 511us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.3273 - accuracy: 0.8630 - 5ms/epoch - 538us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.3520 - accuracy: 0.8699 - 5ms/epoch - 532us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.3581 - accuracy: 0.8699 - 5ms/epoch - 503us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.3800 - accuracy: 0.8425 - 5ms/epoch - 545us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.3671 - accuracy: 0.8288 - 5ms/epoch - 522us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.3312 - accuracy: 0.8630 - 5ms/epoch - 515us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.3274 - accuracy: 0.8767 - 5ms/epoch - 543us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.3077 - accuracy: 0.8733 - 5ms/epoch - 512us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.3161 - accuracy: 0.8767 - 5ms/epoch - 517us/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.3050 - accuracy: 0.8836 - 6ms/epoch - 580us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.3142 - accuracy: 0.8767 - 5ms/epoch - 527us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.3198 - accuracy: 0.8699 - 5ms/epoch - 546us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.3004 - accuracy: 0.8801 - 5ms/epoch - 538us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.2977 - accuracy: 0.8733 - 5ms/epoch - 524us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.2971 - accuracy: 0.8836 - 5ms/epoch - 519us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.3471 - accuracy: 0.8596 - 5ms/epoch - 521us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.3458 - accuracy: 0.8527 - 5ms/epoch - 517us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.3597 - accuracy: 0.8596 - 5ms/epoch - 536us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.3172 - accuracy: 0.8596 - 5ms/epoch - 517us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.3083 - accuracy: 0.8699 - 5ms/epoch - 531us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.3093 - accuracy: 0.8699 - 6ms/epoch - 586us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.3090 - accuracy: 0.8767 - 5ms/epoch - 515us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.2916 - accuracy: 0.8836 - 5ms/epoch - 526us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.2954 - accuracy: 0.8973 - 5ms/epoch - 530us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.3452 - accuracy: 0.8459 - 5ms/epoch - 527us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.3198 - accuracy: 0.8699 - 5ms/epoch - 517us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.2908 - accuracy: 0.9007 - 5ms/epoch - 541us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.2855 - accuracy: 0.8870 - 5ms/epoch - 517us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.2839 - accuracy: 0.8836 - 6ms/epoch - 558us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.2894 - accuracy: 0.8767 - 5ms/epoch - 518us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.2861 - accuracy: 0.9007 - 5ms/epoch - 529us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.2868 - accuracy: 0.9007 - 5ms/epoch - 536us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.3171 - accuracy: 0.8801 - 5ms/epoch - 526us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.3074 - accuracy: 0.8699 - 5ms/epoch - 517us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.2926 - accuracy: 0.8733 - 5ms/epoch - 534us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.3107 - accuracy: 0.8938 - 5ms/epoch - 514us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.2827 - accuracy: 0.8904 - 5ms/epoch - 511us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.3005 - accuracy: 0.8870 - 5ms/epoch - 543us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.2800 - accuracy: 0.8733 - 5ms/epoch - 518us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.2812 - accuracy: 0.8836 - 5ms/epoch - 538us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.2940 - accuracy: 0.8767 - 5ms/epoch - 527us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.3169 - accuracy: 0.8767 - 5ms/epoch - 523us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.2730 - accuracy: 0.8801 - 6ms/epoch - 578us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.2720 - accuracy: 0.8870 - 5ms/epoch - 511us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.3039 - accuracy: 0.8801 - 5ms/epoch - 520us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.2675 - accuracy: 0.8938 - 5ms/epoch - 527us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.2632 - accuracy: 0.8870 - 5ms/epoch - 517us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.2842 - accuracy: 0.8836 - 5ms/epoch - 492us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.2883 - accuracy: 0.8733 - 6ms/epoch - 554us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.2583 - accuracy: 0.8904 - 5ms/epoch - 508us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.2679 - accuracy: 0.8836 - 5ms/epoch - 494us/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.3053 - accuracy: 0.8801 - 5ms/epoch - 535us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.3229 - accuracy: 0.8425 - 5ms/epoch - 519us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.3339 - accuracy: 0.8527 - 5ms/epoch - 492us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.3241 - accuracy: 0.8664 - 6ms/epoch - 562us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.2984 - accuracy: 0.8767 - 5ms/epoch - 506us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.2675 - accuracy: 0.8904 - 6ms/epoch - 557us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.2793 - accuracy: 0.8973 - 6ms/epoch - 556us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.3050 - accuracy: 0.8767 - 6ms/epoch - 578us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.3486 - accuracy: 0.8630 - 6ms/epoch - 569us/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.3418 - accuracy: 0.8527 - 5ms/epoch - 509us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.2834 - accuracy: 0.8870 - 5ms/epoch - 538us/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.3081 - accuracy: 0.8664 - 6ms/epoch - 565us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.2784 - accuracy: 0.8870 - 5ms/epoch - 539us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.2836 - accuracy: 0.8870 - 5ms/epoch - 523us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.2629 - accuracy: 0.8938 - 6ms/epoch - 560us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.2637 - accuracy: 0.9007 - 5ms/epoch - 520us/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.2589 - accuracy: 0.8904 - 5ms/epoch - 525us/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.2544 - accuracy: 0.8973 - 6ms/epoch - 587us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.2732 - accuracy: 0.8904 - 6ms/epoch - 586us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.2570 - accuracy: 0.9041 - 6ms/epoch - 579us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.2568 - accuracy: 0.8973 - 5ms/epoch - 544us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.2595 - accuracy: 0.9007 - 5ms/epoch - 511us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.2454 - accuracy: 0.9007 - 5ms/epoch - 546us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.2443 - accuracy: 0.9007 - 5ms/epoch - 511us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.2475 - accuracy: 0.8938 - 5ms/epoch - 525us/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.2467 - accuracy: 0.9007 - 6ms/epoch - 552us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.2648 - accuracy: 0.8767 - 5ms/epoch - 512us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.2743 - accuracy: 0.9007 - 5ms/epoch - 519us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.2531 - accuracy: 0.8870 - 5ms/epoch - 518us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.2469 - accuracy: 0.8973 - 5ms/epoch - 522us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.2535 - accuracy: 0.8904 - 5ms/epoch - 519us/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.2958 - accuracy: 0.8836 - 5ms/epoch - 524us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.2435 - accuracy: 0.9041 - 5ms/epoch - 503us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.2473 - accuracy: 0.9075 - 5ms/epoch - 539us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.2813 - accuracy: 0.8938 - 5ms/epoch - 529us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.2734 - accuracy: 0.8801 - 5ms/epoch - 515us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.3191 - accuracy: 0.8733 - 6ms/epoch - 553us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.3303 - accuracy: 0.8699 - 5ms/epoch - 536us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.2748 - accuracy: 0.8973 - 5ms/epoch - 504us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.2524 - accuracy: 0.8904 - 6ms/epoch - 576us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.2602 - accuracy: 0.8904 - 5ms/epoch - 521us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.2426 - accuracy: 0.8904 - 6ms/epoch - 575us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.2608 - accuracy: 0.8733 - 5ms/epoch - 536us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.2616 - accuracy: 0.9007 - 5ms/epoch - 496us/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.2639 - accuracy: 0.8767 - 6ms/epoch - 559us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.2765 - accuracy: 0.8904 - 5ms/epoch - 534us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.2650 - accuracy: 0.9007 - 5ms/epoch - 524us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.2620 - accuracy: 0.8973 - 6ms/epoch - 567us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.2603 - accuracy: 0.8904 - 5ms/epoch - 515us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.2435 - accuracy: 0.9041 - 5ms/epoch - 514us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.2584 - accuracy: 0.8938 - 6ms/epoch - 574us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.2352 - accuracy: 0.8938 - 5ms/epoch - 520us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.2326 - accuracy: 0.9075 - 5ms/epoch - 540us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.2351 - accuracy: 0.9144 - 5ms/epoch - 524us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.2532 - accuracy: 0.8870 - 5ms/epoch - 514us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.2498 - accuracy: 0.9041 - 5ms/epoch - 518us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.2637 - accuracy: 0.8801 - 5ms/epoch - 539us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.2417 - accuracy: 0.9075 - 5ms/epoch - 528us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.2540 - accuracy: 0.8904 - 5ms/epoch - 535us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.3186 - accuracy: 0.8596 - 5ms/epoch - 530us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.2824 - accuracy: 0.8630 - 5ms/epoch - 525us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.2783 - accuracy: 0.8767 - 5ms/epoch - 539us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.2800 - accuracy: 0.8836 - 5ms/epoch - 527us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.2434 - accuracy: 0.9041 - 5ms/epoch - 507us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.2777 - accuracy: 0.8904 - 5ms/epoch - 541us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.2552 - accuracy: 0.8699 - 5ms/epoch - 543us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.2456 - accuracy: 0.8836 - 5ms/epoch - 506us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.2340 - accuracy: 0.8973 - 5ms/epoch - 510us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16803ff70>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47502214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3065 - accuracy: 0.9082 - 38ms/epoch - 10ms/step\n",
      "Loss: 0.30653536319732666, Accuracy: 0.9081632494926453\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e14cf",
   "metadata": {},
   "source": [
    "# C&I Loan Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a02310c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observation_date', 'C&I_CO', 'C&I_DELNQ', 'GDP', 'CORP_DEBT_NET_WORTH',\n",
       "       'Manufacturing_Confidence', 'FEDFUNDS', 'CORP_SAVINGS_LEVEL', 'UNRATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create C&I loan dataset\n",
    "CI_df = main_df[['observation_date', 'C&I_CO', 'C&I_DELNQ', 'GDP', 'CORP_DEBT_NET_WORTH', 'Manufacturing_Confidence', 'FEDFUNDS', 'CORP_SAVINGS_LEVEL', 'UNRATE']]\n",
    "\n",
    "CI_bin_df = mort_df.copy()\n",
    "\n",
    "CI_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d088b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C&amp;I_DELNQ</th>\n",
       "      <th>GDP</th>\n",
       "      <th>CORP_DEBT_NET_WORTH</th>\n",
       "      <th>Manufacturing_Confidence</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>CORP_SAVINGS_LEVEL</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.29</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>96.951745</td>\n",
       "      <td>6.91</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.29</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>96.972896</td>\n",
       "      <td>6.25</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.29</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>97.223425</td>\n",
       "      <td>6.12</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>46.289579</td>\n",
       "      <td>97.678049</td>\n",
       "      <td>5.91</td>\n",
       "      <td>81.294</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>46.289579</td>\n",
       "      <td>98.292261</td>\n",
       "      <td>5.78</td>\n",
       "      <td>81.294</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.98</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.497128</td>\n",
       "      <td>98.951152</td>\n",
       "      <td>4.57</td>\n",
       "      <td>263.194</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.98</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.497128</td>\n",
       "      <td>98.913862</td>\n",
       "      <td>4.65</td>\n",
       "      <td>263.194</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1.01</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.904602</td>\n",
       "      <td>4.83</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1.01</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.887364</td>\n",
       "      <td>5.06</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1.01</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.872005</td>\n",
       "      <td>5.08</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C&I_DELNQ  GDP  CORP_DEBT_NET_WORTH  Manufacturing_Confidence  FEDFUNDS  \\\n",
       "0         6.29 -1.9            46.132964                 96.951745      6.91   \n",
       "1         6.29 -1.9            46.132964                 96.972896      6.25   \n",
       "2         6.29 -1.9            46.132964                 97.223425      6.12   \n",
       "3         6.41  3.2            46.289579                 97.678049      5.91   \n",
       "4         6.41  3.2            46.289579                 98.292261      5.78   \n",
       "..         ...  ...                  ...                       ...       ...   \n",
       "385       0.98  2.2            40.497128                 98.951152      4.57   \n",
       "386       0.98  2.2            40.497128                 98.913862      4.65   \n",
       "387       1.01  2.1            39.659559                 98.904602      4.83   \n",
       "388       1.01  2.1            39.659559                 98.887364      5.06   \n",
       "389       1.01  2.1            39.659559                 98.872005      5.08   \n",
       "\n",
       "     CORP_SAVINGS_LEVEL  UNRATE  \n",
       "0                77.964     6.4  \n",
       "1                77.964     6.6  \n",
       "2                77.964     6.8  \n",
       "3                81.294     6.7  \n",
       "4                81.294     6.9  \n",
       "..                  ...     ...  \n",
       "385             263.194     3.6  \n",
       "386             263.194     3.5  \n",
       "387             367.036     3.4  \n",
       "388             367.036     3.7  \n",
       "389             367.036     3.6  \n",
       "\n",
       "[390 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binning the data for classification Question: \n",
    "CI_bin_df[\"C&I_CO_BIN\"] = pd.qcut(CI_df['C&I_CO'],4, labels= [1, 2, 3, 4])\n",
    "\n",
    "# Define the dependent Y variable\n",
    "y = CI_bin_df[\"C&I_CO_BIN\"]\n",
    "\n",
    "CI_df = CI_df.drop(columns=['C&I_CO','observation_date'])\n",
    "CI_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d70353",
   "metadata": {},
   "source": [
    "# Deep Learning: C&I Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b0fb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ccard_df, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5db19197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26ab3ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set shape:  (292, 7)\n",
      "y_train set shape:  (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train set shape: \", X_train_scaled.shape)\n",
    "print(\"y_train set shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c1f32aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 2, 1, ..., 1, 2, 3, 2, 3]\n",
       "Length: 292\n",
       "Categories (4, int64): [1 < 2 < 3 < 4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7967441e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = to_categorical(y_train.values, num_classes)\n",
    "y_test = to_categorical(y_test.values, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdcf7f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 205       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11385 (44.47 KB)\n",
      "Trainable params: 11385 (44.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layers1 = 60\n",
    "hidden_nodes_layers2 = 60\n",
    "hidden_nodes_layers3 = 60\n",
    "hidden_nodes_layers4 = 40\n",
    "\n",
    "\n",
    "model.add(Dense(20, activation='relu', input_dim=number_input_features))\n",
    "model.add(Dense(hidden_nodes_layers1, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers2, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers3, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers4, activation='relu'))\n",
    "# model.add(Dense(hidden_nodes_layers5, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "591ca2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 1.5724 - accuracy: 0.2260 - 130ms/epoch - 13ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 1.4997 - accuracy: 0.2397 - 5ms/epoch - 505us/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 1.4313 - accuracy: 0.2842 - 5ms/epoch - 496us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.3661 - accuracy: 0.4760 - 5ms/epoch - 520us/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.3157 - accuracy: 0.4760 - 5ms/epoch - 535us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 1.2614 - accuracy: 0.5068 - 5ms/epoch - 461us/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 1.1982 - accuracy: 0.4315 - 5ms/epoch - 481us/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 1.1288 - accuracy: 0.4658 - 5ms/epoch - 467us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 1.0642 - accuracy: 0.4863 - 5ms/epoch - 485us/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 1.0423 - accuracy: 0.4829 - 5ms/epoch - 544us/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 1.0096 - accuracy: 0.5411 - 5ms/epoch - 519us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.9915 - accuracy: 0.5068 - 6ms/epoch - 564us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.9750 - accuracy: 0.4966 - 5ms/epoch - 549us/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.9440 - accuracy: 0.5445 - 5ms/epoch - 516us/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.9332 - accuracy: 0.5411 - 5ms/epoch - 537us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.9188 - accuracy: 0.5411 - 5ms/epoch - 530us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.9160 - accuracy: 0.5479 - 5ms/epoch - 519us/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.9205 - accuracy: 0.5479 - 6ms/epoch - 556us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.8977 - accuracy: 0.5856 - 5ms/epoch - 530us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.9008 - accuracy: 0.5548 - 5ms/epoch - 526us/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.9143 - accuracy: 0.5685 - 5ms/epoch - 537us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.8749 - accuracy: 0.5685 - 5ms/epoch - 539us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.8952 - accuracy: 0.5548 - 6ms/epoch - 566us/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.8785 - accuracy: 0.5822 - 6ms/epoch - 558us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.8610 - accuracy: 0.5822 - 5ms/epoch - 519us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.8532 - accuracy: 0.6164 - 6ms/epoch - 602us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.8446 - accuracy: 0.5651 - 5ms/epoch - 515us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.8275 - accuracy: 0.6267 - 5ms/epoch - 513us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.8210 - accuracy: 0.6164 - 5ms/epoch - 520us/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.8129 - accuracy: 0.6473 - 5ms/epoch - 520us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.8807 - accuracy: 0.5959 - 5ms/epoch - 497us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.8203 - accuracy: 0.6301 - 6ms/epoch - 575us/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.8070 - accuracy: 0.6096 - 5ms/epoch - 524us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.8036 - accuracy: 0.6096 - 5ms/epoch - 516us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.7922 - accuracy: 0.6370 - 6ms/epoch - 595us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.7836 - accuracy: 0.6267 - 5ms/epoch - 543us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.7671 - accuracy: 0.6473 - 5ms/epoch - 534us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.7694 - accuracy: 0.6336 - 5ms/epoch - 549us/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.7548 - accuracy: 0.6404 - 5ms/epoch - 512us/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.7577 - accuracy: 0.6507 - 6ms/epoch - 580us/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.7688 - accuracy: 0.6199 - 5ms/epoch - 537us/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.7369 - accuracy: 0.6610 - 5ms/epoch - 539us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.8066 - accuracy: 0.6301 - 6ms/epoch - 591us/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.7526 - accuracy: 0.6781 - 5ms/epoch - 519us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.7396 - accuracy: 0.6541 - 6ms/epoch - 559us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.7415 - accuracy: 0.6712 - 5ms/epoch - 540us/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.7373 - accuracy: 0.6473 - 5ms/epoch - 527us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.7259 - accuracy: 0.6644 - 5ms/epoch - 550us/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.7351 - accuracy: 0.6575 - 5ms/epoch - 526us/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.7465 - accuracy: 0.6336 - 5ms/epoch - 523us/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.7317 - accuracy: 0.6781 - 6ms/epoch - 553us/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.7394 - accuracy: 0.6199 - 5ms/epoch - 540us/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.7155 - accuracy: 0.6370 - 5ms/epoch - 497us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.7285 - accuracy: 0.7021 - 6ms/epoch - 572us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.6936 - accuracy: 0.6610 - 5ms/epoch - 536us/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.6892 - accuracy: 0.6849 - 6ms/epoch - 560us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.6911 - accuracy: 0.6986 - 5ms/epoch - 537us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.6788 - accuracy: 0.7055 - 5ms/epoch - 518us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.7006 - accuracy: 0.6712 - 6ms/epoch - 608us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.6948 - accuracy: 0.6952 - 5ms/epoch - 526us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.6856 - accuracy: 0.6918 - 5ms/epoch - 514us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.7000 - accuracy: 0.6404 - 6ms/epoch - 555us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.6751 - accuracy: 0.7089 - 5ms/epoch - 505us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.6632 - accuracy: 0.6918 - 5ms/epoch - 503us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.6769 - accuracy: 0.6918 - 5ms/epoch - 540us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.6606 - accuracy: 0.7192 - 5ms/epoch - 531us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.6445 - accuracy: 0.7055 - 5ms/epoch - 525us/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.6583 - accuracy: 0.6884 - 5ms/epoch - 540us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.6404 - accuracy: 0.7158 - 5ms/epoch - 510us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.6876 - accuracy: 0.6986 - 5ms/epoch - 536us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.6504 - accuracy: 0.7226 - 5ms/epoch - 527us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.6300 - accuracy: 0.7089 - 5ms/epoch - 508us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.6271 - accuracy: 0.7226 - 5ms/epoch - 513us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.6371 - accuracy: 0.7192 - 5ms/epoch - 528us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.6341 - accuracy: 0.7158 - 5ms/epoch - 519us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.6384 - accuracy: 0.6884 - 5ms/epoch - 533us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.6177 - accuracy: 0.6918 - 6ms/epoch - 552us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.6769 - accuracy: 0.6678 - 5ms/epoch - 513us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.6188 - accuracy: 0.6986 - 5ms/epoch - 490us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.6058 - accuracy: 0.7158 - 5ms/epoch - 532us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.6094 - accuracy: 0.7158 - 5ms/epoch - 510us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.5929 - accuracy: 0.7295 - 6ms/epoch - 557us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.5999 - accuracy: 0.7397 - 5ms/epoch - 512us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.6187 - accuracy: 0.7123 - 5ms/epoch - 525us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.6654 - accuracy: 0.6815 - 5ms/epoch - 526us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.6257 - accuracy: 0.7226 - 5ms/epoch - 521us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.6058 - accuracy: 0.7397 - 5ms/epoch - 533us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.5909 - accuracy: 0.7329 - 5ms/epoch - 537us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.6746 - accuracy: 0.6918 - 5ms/epoch - 519us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.5927 - accuracy: 0.7432 - 6ms/epoch - 566us/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.5662 - accuracy: 0.7363 - 5ms/epoch - 536us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.6006 - accuracy: 0.7397 - 5ms/epoch - 535us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.5885 - accuracy: 0.7363 - 6ms/epoch - 564us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.5830 - accuracy: 0.7260 - 5ms/epoch - 549us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.5566 - accuracy: 0.7363 - 5ms/epoch - 523us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.6192 - accuracy: 0.7089 - 6ms/epoch - 566us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.5761 - accuracy: 0.7432 - 5ms/epoch - 529us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.5963 - accuracy: 0.7397 - 5ms/epoch - 533us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.5832 - accuracy: 0.7432 - 6ms/epoch - 552us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.5788 - accuracy: 0.7466 - 5ms/epoch - 540us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.5735 - accuracy: 0.7260 - 6ms/epoch - 568us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.5699 - accuracy: 0.7192 - 5ms/epoch - 540us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.5597 - accuracy: 0.7500 - 5ms/epoch - 511us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.5558 - accuracy: 0.7500 - 6ms/epoch - 566us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.5540 - accuracy: 0.7568 - 5ms/epoch - 521us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.5571 - accuracy: 0.7260 - 5ms/epoch - 523us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.5636 - accuracy: 0.7397 - 6ms/epoch - 563us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.5499 - accuracy: 0.7534 - 5ms/epoch - 536us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.5532 - accuracy: 0.7397 - 5ms/epoch - 518us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.5915 - accuracy: 0.7089 - 6ms/epoch - 558us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.5569 - accuracy: 0.7397 - 5ms/epoch - 507us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.5634 - accuracy: 0.7705 - 5ms/epoch - 545us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.5446 - accuracy: 0.7432 - 5ms/epoch - 525us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.5671 - accuracy: 0.7260 - 5ms/epoch - 520us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.5967 - accuracy: 0.7158 - 6ms/epoch - 551us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.5497 - accuracy: 0.7603 - 5ms/epoch - 536us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.5449 - accuracy: 0.7534 - 5ms/epoch - 526us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.5162 - accuracy: 0.7637 - 6ms/epoch - 558us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.5609 - accuracy: 0.7568 - 5ms/epoch - 531us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.5122 - accuracy: 0.7705 - 5ms/epoch - 509us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.5175 - accuracy: 0.7705 - 5ms/epoch - 500us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.5112 - accuracy: 0.7603 - 5ms/epoch - 527us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.5640 - accuracy: 0.7568 - 5ms/epoch - 543us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.5435 - accuracy: 0.7397 - 5ms/epoch - 523us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.5550 - accuracy: 0.7534 - 5ms/epoch - 522us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.5426 - accuracy: 0.7329 - 5ms/epoch - 516us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.5145 - accuracy: 0.7568 - 5ms/epoch - 494us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.5540 - accuracy: 0.7329 - 5ms/epoch - 520us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.5164 - accuracy: 0.7705 - 5ms/epoch - 523us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.4861 - accuracy: 0.7945 - 5ms/epoch - 530us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.5463 - accuracy: 0.7500 - 5ms/epoch - 531us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.5154 - accuracy: 0.7568 - 5ms/epoch - 503us/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.5262 - accuracy: 0.7740 - 5ms/epoch - 504us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.5133 - accuracy: 0.7637 - 5ms/epoch - 525us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.5143 - accuracy: 0.7740 - 6ms/epoch - 610us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.5239 - accuracy: 0.7397 - 5ms/epoch - 531us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.4900 - accuracy: 0.7979 - 5ms/epoch - 538us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.4855 - accuracy: 0.7740 - 6ms/epoch - 553us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.5179 - accuracy: 0.7432 - 5ms/epoch - 534us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.4853 - accuracy: 0.7842 - 5ms/epoch - 516us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.4755 - accuracy: 0.7705 - 5ms/epoch - 503us/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.4812 - accuracy: 0.7842 - 6ms/epoch - 560us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.4761 - accuracy: 0.7774 - 5ms/epoch - 501us/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.5267 - accuracy: 0.7500 - 5ms/epoch - 485us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.4680 - accuracy: 0.7911 - 5ms/epoch - 518us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.4520 - accuracy: 0.7945 - 5ms/epoch - 519us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.4693 - accuracy: 0.7842 - 5ms/epoch - 535us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.5032 - accuracy: 0.7603 - 5ms/epoch - 514us/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.4720 - accuracy: 0.7842 - 5ms/epoch - 548us/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.6159 - accuracy: 0.7260 - 5ms/epoch - 515us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.5054 - accuracy: 0.7637 - 5ms/epoch - 504us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.4840 - accuracy: 0.7808 - 5ms/epoch - 516us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.4841 - accuracy: 0.8116 - 5ms/epoch - 525us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.4825 - accuracy: 0.7740 - 5ms/epoch - 519us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.4576 - accuracy: 0.8014 - 5ms/epoch - 514us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.4507 - accuracy: 0.7842 - 5ms/epoch - 547us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.4801 - accuracy: 0.7877 - 5ms/epoch - 516us/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.5060 - accuracy: 0.7568 - 6ms/epoch - 553us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.4732 - accuracy: 0.7842 - 5ms/epoch - 520us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.4680 - accuracy: 0.7705 - 5ms/epoch - 508us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.4733 - accuracy: 0.7945 - 5ms/epoch - 545us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.4562 - accuracy: 0.7740 - 5ms/epoch - 524us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.4681 - accuracy: 0.7911 - 5ms/epoch - 526us/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.4604 - accuracy: 0.7842 - 6ms/epoch - 560us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.4343 - accuracy: 0.7979 - 5ms/epoch - 515us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.4363 - accuracy: 0.7877 - 5ms/epoch - 546us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.4467 - accuracy: 0.8048 - 5ms/epoch - 527us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.4395 - accuracy: 0.7979 - 5ms/epoch - 515us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.4416 - accuracy: 0.7877 - 5ms/epoch - 542us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.4528 - accuracy: 0.7877 - 5ms/epoch - 518us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.4791 - accuracy: 0.7911 - 5ms/epoch - 533us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.5443 - accuracy: 0.7432 - 5ms/epoch - 543us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.4759 - accuracy: 0.7774 - 5ms/epoch - 528us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.4240 - accuracy: 0.8014 - 5ms/epoch - 515us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.4157 - accuracy: 0.8253 - 5ms/epoch - 500us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.4104 - accuracy: 0.8082 - 5ms/epoch - 523us/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.4011 - accuracy: 0.8048 - 6ms/epoch - 586us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.4276 - accuracy: 0.8048 - 5ms/epoch - 538us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.4395 - accuracy: 0.7842 - 5ms/epoch - 524us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.4337 - accuracy: 0.7911 - 5ms/epoch - 543us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.4087 - accuracy: 0.8048 - 5ms/epoch - 520us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.3954 - accuracy: 0.8151 - 5ms/epoch - 524us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.3914 - accuracy: 0.8116 - 6ms/epoch - 550us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.3920 - accuracy: 0.8185 - 5ms/epoch - 523us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.3973 - accuracy: 0.7979 - 5ms/epoch - 516us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.3793 - accuracy: 0.8185 - 6ms/epoch - 551us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.4032 - accuracy: 0.7911 - 5ms/epoch - 535us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.4099 - accuracy: 0.8185 - 5ms/epoch - 523us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.3770 - accuracy: 0.8356 - 6ms/epoch - 571us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.3735 - accuracy: 0.8459 - 5ms/epoch - 522us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.3919 - accuracy: 0.8185 - 5ms/epoch - 541us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.4337 - accuracy: 0.8082 - 5ms/epoch - 537us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.4448 - accuracy: 0.7979 - 5ms/epoch - 536us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.7532 - accuracy: 0.7260 - 5ms/epoch - 540us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.7024 - accuracy: 0.6849 - 5ms/epoch - 521us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.4769 - accuracy: 0.7637 - 5ms/epoch - 513us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.4959 - accuracy: 0.7568 - 6ms/epoch - 576us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.4659 - accuracy: 0.8116 - 5ms/epoch - 517us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.4245 - accuracy: 0.7979 - 5ms/epoch - 517us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.3913 - accuracy: 0.8185 - 5ms/epoch - 540us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16803d720>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cddb8015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.6497 - accuracy: 0.7449 - 55ms/epoch - 14ms/step\n",
      "Loss: 0.6496942043304443, Accuracy: 0.7448979616165161\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06451517",
   "metadata": {},
   "source": [
    "# CRE Loan Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "974fa4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observation_date', 'CRE_CO', 'CRE_DELNQ', 'Rental_Vacancy_Rate', 'GDP',\n",
       "       'CORP_DEBT_NET_WORTH', 'Manufacturing_Confidence', 'FEDFUNDS',\n",
       "       'CORP_SAVINGS_LEVEL', 'UNRATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create CRE loan dataset\n",
    "CRE_df = main_df[['observation_date', 'CRE_CO', 'CRE_DELNQ', 'Rental_Vacancy_Rate', 'GDP', 'CORP_DEBT_NET_WORTH', 'Manufacturing_Confidence', 'FEDFUNDS', 'CORP_SAVINGS_LEVEL', 'UNRATE']]\n",
    "\n",
    "CRE_bin_df = mort_df.copy()\n",
    "\n",
    "CRE_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb8ab125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRE_DELNQ</th>\n",
       "      <th>Rental_Vacancy_Rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>CORP_DEBT_NET_WORTH</th>\n",
       "      <th>Manufacturing_Confidence</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>CORP_SAVINGS_LEVEL</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.08</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>96.951745</td>\n",
       "      <td>6.91</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.08</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>96.972896</td>\n",
       "      <td>6.25</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.08</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>97.223425</td>\n",
       "      <td>6.12</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.82</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>46.289579</td>\n",
       "      <td>97.678049</td>\n",
       "      <td>5.91</td>\n",
       "      <td>81.294</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.82</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>46.289579</td>\n",
       "      <td>98.292261</td>\n",
       "      <td>5.78</td>\n",
       "      <td>81.294</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.77</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.497128</td>\n",
       "      <td>98.951152</td>\n",
       "      <td>4.57</td>\n",
       "      <td>263.194</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.77</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.497128</td>\n",
       "      <td>98.913862</td>\n",
       "      <td>4.65</td>\n",
       "      <td>263.194</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.84</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.904602</td>\n",
       "      <td>4.83</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.84</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.887364</td>\n",
       "      <td>5.06</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.84</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.872005</td>\n",
       "      <td>5.08</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRE_DELNQ  Rental_Vacancy_Rate  GDP  CORP_DEBT_NET_WORTH  \\\n",
       "0        12.08                  7.5 -1.9            46.132964   \n",
       "1        12.08                  7.5 -1.9            46.132964   \n",
       "2        12.08                  7.5 -1.9            46.132964   \n",
       "3        11.82                  7.3  3.2            46.289579   \n",
       "4        11.82                  7.3  3.2            46.289579   \n",
       "..         ...                  ...  ...                  ...   \n",
       "385       0.77                  6.4  2.2            40.497128   \n",
       "386       0.77                  6.4  2.2            40.497128   \n",
       "387       0.84                  6.3  2.1            39.659559   \n",
       "388       0.84                  6.3  2.1            39.659559   \n",
       "389       0.84                  6.3  2.1            39.659559   \n",
       "\n",
       "     Manufacturing_Confidence  FEDFUNDS  CORP_SAVINGS_LEVEL  UNRATE  \n",
       "0                   96.951745      6.91              77.964     6.4  \n",
       "1                   96.972896      6.25              77.964     6.6  \n",
       "2                   97.223425      6.12              77.964     6.8  \n",
       "3                   97.678049      5.91              81.294     6.7  \n",
       "4                   98.292261      5.78              81.294     6.9  \n",
       "..                        ...       ...                 ...     ...  \n",
       "385                 98.951152      4.57             263.194     3.6  \n",
       "386                 98.913862      4.65             263.194     3.5  \n",
       "387                 98.904602      4.83             367.036     3.4  \n",
       "388                 98.887364      5.06             367.036     3.7  \n",
       "389                 98.872005      5.08             367.036     3.6  \n",
       "\n",
       "[390 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binning the data for classification Question: \n",
    "CRE_bin_df[\"CRE_CO_BIN\"] = pd.qcut(CRE_df['CRE_CO'],4, labels= [1, 2, 3, 4])\n",
    "\n",
    "# Define the dependent Y variable\n",
    "y = CRE_bin_df[\"CRE_CO_BIN\"]\n",
    "\n",
    "CRE_df = CRE_df.drop(columns=['CRE_CO','observation_date'])\n",
    "CRE_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90154201",
   "metadata": {},
   "source": [
    "# Machine Learning: CRE Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d27e48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ccard_df, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01b8ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75c3879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set shape:  (292, 7)\n",
      "y_train set shape:  (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train set shape: \", X_train_scaled.shape)\n",
    "print(\"y_train set shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1fb2cc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 2, 3, ..., 2, 1, 1, 4, 3]\n",
       "Length: 292\n",
       "Categories (4, int64): [1 < 2 < 3 < 4]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "354ee1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = to_categorical(y_train.values, num_classes)\n",
    "y_test = to_categorical(y_test.values, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "808337ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 205       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11385 (44.47 KB)\n",
      "Trainable params: 11385 (44.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layers1 = 60\n",
    "hidden_nodes_layers2 = 60\n",
    "hidden_nodes_layers3 = 60\n",
    "hidden_nodes_layers4 = 40\n",
    "\n",
    "\n",
    "model.add(Dense(20, activation='relu', input_dim=number_input_features))\n",
    "model.add(Dense(hidden_nodes_layers1, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers2, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers3, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers4, activation='relu'))\n",
    "# model.add(Dense(hidden_nodes_layers5, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "359fae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 1.5581 - accuracy: 0.2534 - 133ms/epoch - 13ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 1.4651 - accuracy: 0.2534 - 5ms/epoch - 535us/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 1.4011 - accuracy: 0.2603 - 6ms/epoch - 568us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.3522 - accuracy: 0.2842 - 5ms/epoch - 509us/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.3051 - accuracy: 0.4178 - 5ms/epoch - 535us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 1.2410 - accuracy: 0.5411 - 5ms/epoch - 503us/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 1.1636 - accuracy: 0.5000 - 5ms/epoch - 468us/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 1.0644 - accuracy: 0.5616 - 5ms/epoch - 525us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 0.9894 - accuracy: 0.5753 - 5ms/epoch - 469us/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.9204 - accuracy: 0.6541 - 5ms/epoch - 510us/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.8531 - accuracy: 0.6712 - 6ms/epoch - 559us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.8383 - accuracy: 0.6301 - 5ms/epoch - 522us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.8019 - accuracy: 0.6610 - 5ms/epoch - 520us/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.7678 - accuracy: 0.6815 - 6ms/epoch - 567us/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.6995 - accuracy: 0.7637 - 5ms/epoch - 531us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.6650 - accuracy: 0.7740 - 6ms/epoch - 561us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.6287 - accuracy: 0.7911 - 5ms/epoch - 545us/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.6120 - accuracy: 0.7774 - 5ms/epoch - 521us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.5914 - accuracy: 0.7774 - 6ms/epoch - 575us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.5886 - accuracy: 0.7568 - 5ms/epoch - 539us/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.5721 - accuracy: 0.7705 - 5ms/epoch - 511us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.5301 - accuracy: 0.7979 - 6ms/epoch - 554us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.5127 - accuracy: 0.8116 - 6ms/epoch - 555us/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.5249 - accuracy: 0.7842 - 5ms/epoch - 523us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.4955 - accuracy: 0.7945 - 6ms/epoch - 569us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.4820 - accuracy: 0.8082 - 5ms/epoch - 526us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.4683 - accuracy: 0.8014 - 6ms/epoch - 591us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.4840 - accuracy: 0.7979 - 5ms/epoch - 540us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.4917 - accuracy: 0.8082 - 5ms/epoch - 523us/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.4797 - accuracy: 0.8185 - 5ms/epoch - 542us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.4680 - accuracy: 0.8151 - 5ms/epoch - 543us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.4644 - accuracy: 0.8356 - 5ms/epoch - 535us/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.4633 - accuracy: 0.7911 - 6ms/epoch - 591us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.4649 - accuracy: 0.8082 - 5ms/epoch - 525us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.4518 - accuracy: 0.8219 - 5ms/epoch - 512us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.4285 - accuracy: 0.8322 - 5ms/epoch - 544us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.4218 - accuracy: 0.8219 - 5ms/epoch - 513us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.4294 - accuracy: 0.8288 - 5ms/epoch - 522us/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.6011 - accuracy: 0.7808 - 6ms/epoch - 565us/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.5114 - accuracy: 0.8116 - 5ms/epoch - 529us/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.4644 - accuracy: 0.8356 - 6ms/epoch - 554us/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.4065 - accuracy: 0.8459 - 5ms/epoch - 520us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.4283 - accuracy: 0.8253 - 5ms/epoch - 507us/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.4204 - accuracy: 0.8390 - 6ms/epoch - 568us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.4095 - accuracy: 0.8253 - 5ms/epoch - 535us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.4114 - accuracy: 0.8493 - 5ms/epoch - 506us/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.4083 - accuracy: 0.8425 - 6ms/epoch - 550us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.3986 - accuracy: 0.8425 - 5ms/epoch - 536us/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.3962 - accuracy: 0.8425 - 5ms/epoch - 536us/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.3850 - accuracy: 0.8493 - 5ms/epoch - 522us/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.3861 - accuracy: 0.8699 - 5ms/epoch - 512us/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.4112 - accuracy: 0.8253 - 6ms/epoch - 581us/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.3974 - accuracy: 0.8493 - 5ms/epoch - 514us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.3874 - accuracy: 0.8425 - 5ms/epoch - 500us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.3752 - accuracy: 0.8596 - 5ms/epoch - 547us/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.4277 - accuracy: 0.8425 - 6ms/epoch - 555us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.3936 - accuracy: 0.8459 - 5ms/epoch - 532us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.3816 - accuracy: 0.8390 - 6ms/epoch - 551us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.3771 - accuracy: 0.8493 - 5ms/epoch - 521us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.3603 - accuracy: 0.8733 - 6ms/epoch - 554us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.3689 - accuracy: 0.8527 - 5ms/epoch - 537us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.3910 - accuracy: 0.8356 - 5ms/epoch - 520us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.4135 - accuracy: 0.8459 - 5ms/epoch - 523us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.3781 - accuracy: 0.8493 - 5ms/epoch - 499us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.3737 - accuracy: 0.8562 - 5ms/epoch - 520us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.3633 - accuracy: 0.8630 - 5ms/epoch - 535us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.3656 - accuracy: 0.8527 - 5ms/epoch - 525us/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.3443 - accuracy: 0.8836 - 5ms/epoch - 519us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.3672 - accuracy: 0.8664 - 5ms/epoch - 532us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.3916 - accuracy: 0.8527 - 5ms/epoch - 515us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.3783 - accuracy: 0.8562 - 5ms/epoch - 511us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.3602 - accuracy: 0.8733 - 6ms/epoch - 558us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.3403 - accuracy: 0.8801 - 5ms/epoch - 522us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.3461 - accuracy: 0.8767 - 5ms/epoch - 523us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.3407 - accuracy: 0.8664 - 5ms/epoch - 531us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.3431 - accuracy: 0.8664 - 5ms/epoch - 527us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.3635 - accuracy: 0.8562 - 5ms/epoch - 515us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.3734 - accuracy: 0.8596 - 6ms/epoch - 566us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.4982 - accuracy: 0.7808 - 5ms/epoch - 523us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.4238 - accuracy: 0.8151 - 6ms/epoch - 552us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.3866 - accuracy: 0.8425 - 5ms/epoch - 515us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.3601 - accuracy: 0.8562 - 5ms/epoch - 529us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.3394 - accuracy: 0.8767 - 5ms/epoch - 546us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.3504 - accuracy: 0.8562 - 5ms/epoch - 516us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.3361 - accuracy: 0.8699 - 5ms/epoch - 521us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.3333 - accuracy: 0.8836 - 6ms/epoch - 559us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.3430 - accuracy: 0.8733 - 5ms/epoch - 518us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.3453 - accuracy: 0.8767 - 5ms/epoch - 525us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.3814 - accuracy: 0.8596 - 6ms/epoch - 554us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.3637 - accuracy: 0.8562 - 5ms/epoch - 533us/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.3256 - accuracy: 0.8904 - 5ms/epoch - 514us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.3164 - accuracy: 0.8904 - 5ms/epoch - 530us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.3026 - accuracy: 0.9007 - 5ms/epoch - 522us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.3089 - accuracy: 0.8904 - 5ms/epoch - 528us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.3117 - accuracy: 0.8801 - 5ms/epoch - 516us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.3488 - accuracy: 0.8562 - 5ms/epoch - 502us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.3388 - accuracy: 0.8630 - 5ms/epoch - 542us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.3715 - accuracy: 0.8562 - 5ms/epoch - 516us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.3520 - accuracy: 0.8664 - 5ms/epoch - 522us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.4064 - accuracy: 0.8390 - 5ms/epoch - 550us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.3808 - accuracy: 0.8596 - 5ms/epoch - 515us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.3201 - accuracy: 0.8904 - 5ms/epoch - 529us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.3085 - accuracy: 0.8836 - 5ms/epoch - 533us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.3677 - accuracy: 0.8596 - 5ms/epoch - 508us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.3088 - accuracy: 0.8973 - 5ms/epoch - 522us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.3315 - accuracy: 0.8733 - 6ms/epoch - 578us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.3033 - accuracy: 0.8904 - 5ms/epoch - 522us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.3047 - accuracy: 0.8904 - 5ms/epoch - 531us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.2905 - accuracy: 0.9110 - 5ms/epoch - 513us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.2872 - accuracy: 0.9144 - 5ms/epoch - 520us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.2891 - accuracy: 0.9144 - 5ms/epoch - 545us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.2792 - accuracy: 0.9075 - 5ms/epoch - 522us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.2800 - accuracy: 0.9110 - 5ms/epoch - 512us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.2874 - accuracy: 0.9041 - 5ms/epoch - 521us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.3079 - accuracy: 0.8767 - 5ms/epoch - 518us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.2979 - accuracy: 0.8836 - 5ms/epoch - 520us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.2929 - accuracy: 0.9007 - 5ms/epoch - 540us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.2886 - accuracy: 0.9007 - 5ms/epoch - 521us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.3259 - accuracy: 0.8904 - 5ms/epoch - 488us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.3000 - accuracy: 0.8870 - 5ms/epoch - 536us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.2875 - accuracy: 0.8973 - 5ms/epoch - 518us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.2851 - accuracy: 0.8938 - 5ms/epoch - 508us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.3020 - accuracy: 0.8836 - 5ms/epoch - 514us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.3292 - accuracy: 0.8630 - 5ms/epoch - 520us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.3293 - accuracy: 0.8836 - 5ms/epoch - 514us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.2956 - accuracy: 0.9041 - 6ms/epoch - 559us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.2969 - accuracy: 0.8870 - 5ms/epoch - 524us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.2669 - accuracy: 0.9075 - 6ms/epoch - 551us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.2956 - accuracy: 0.8938 - 5ms/epoch - 520us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.3045 - accuracy: 0.8938 - 5ms/epoch - 541us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.2794 - accuracy: 0.8938 - 5ms/epoch - 548us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.3137 - accuracy: 0.8664 - 5ms/epoch - 521us/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.2806 - accuracy: 0.8904 - 5ms/epoch - 532us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.2650 - accuracy: 0.9041 - 6ms/epoch - 572us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.2596 - accuracy: 0.9144 - 5ms/epoch - 516us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.2635 - accuracy: 0.9110 - 5ms/epoch - 524us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.2655 - accuracy: 0.9007 - 5ms/epoch - 540us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.2617 - accuracy: 0.9075 - 5ms/epoch - 519us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.2575 - accuracy: 0.9075 - 5ms/epoch - 511us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.2638 - accuracy: 0.9075 - 5ms/epoch - 544us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.2920 - accuracy: 0.8904 - 5ms/epoch - 524us/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.2543 - accuracy: 0.9075 - 5ms/epoch - 526us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.2755 - accuracy: 0.8836 - 6ms/epoch - 582us/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.2675 - accuracy: 0.9007 - 4ms/epoch - 450us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.2939 - accuracy: 0.8938 - 5ms/epoch - 503us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.3178 - accuracy: 0.8733 - 5ms/epoch - 525us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.2918 - accuracy: 0.8870 - 5ms/epoch - 515us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.2812 - accuracy: 0.8938 - 5ms/epoch - 520us/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.2678 - accuracy: 0.8836 - 5ms/epoch - 533us/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.2517 - accuracy: 0.9110 - 5ms/epoch - 510us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.2479 - accuracy: 0.9075 - 5ms/epoch - 517us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.2639 - accuracy: 0.9075 - 5ms/epoch - 523us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.2536 - accuracy: 0.9144 - 5ms/epoch - 518us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.2538 - accuracy: 0.9075 - 6ms/epoch - 551us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.2671 - accuracy: 0.8938 - 5ms/epoch - 530us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.2388 - accuracy: 0.9178 - 5ms/epoch - 509us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.2562 - accuracy: 0.9075 - 5ms/epoch - 542us/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.2520 - accuracy: 0.9247 - 5ms/epoch - 522us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.2924 - accuracy: 0.8836 - 5ms/epoch - 524us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.2847 - accuracy: 0.9041 - 6ms/epoch - 557us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.2647 - accuracy: 0.9075 - 5ms/epoch - 544us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.2574 - accuracy: 0.8904 - 5ms/epoch - 532us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.3224 - accuracy: 0.8801 - 5ms/epoch - 530us/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.2954 - accuracy: 0.8699 - 5ms/epoch - 531us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.2741 - accuracy: 0.9041 - 5ms/epoch - 532us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.2818 - accuracy: 0.8904 - 5ms/epoch - 531us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.2944 - accuracy: 0.8973 - 5ms/epoch - 497us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.3171 - accuracy: 0.8459 - 5ms/epoch - 541us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.2666 - accuracy: 0.9041 - 5ms/epoch - 521us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.2397 - accuracy: 0.9110 - 5ms/epoch - 511us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.2539 - accuracy: 0.9007 - 5ms/epoch - 550us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.2697 - accuracy: 0.8904 - 5ms/epoch - 522us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.2469 - accuracy: 0.9075 - 5ms/epoch - 526us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.2931 - accuracy: 0.8938 - 6ms/epoch - 553us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.3178 - accuracy: 0.8630 - 5ms/epoch - 519us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.2796 - accuracy: 0.8938 - 5ms/epoch - 545us/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.2355 - accuracy: 0.9178 - 5ms/epoch - 528us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.2225 - accuracy: 0.9178 - 6ms/epoch - 553us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.2662 - accuracy: 0.8938 - 6ms/epoch - 551us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.2397 - accuracy: 0.9144 - 5ms/epoch - 536us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.2248 - accuracy: 0.9212 - 5ms/epoch - 526us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.2436 - accuracy: 0.9041 - 6ms/epoch - 573us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.2456 - accuracy: 0.9144 - 5ms/epoch - 523us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.2298 - accuracy: 0.9075 - 5ms/epoch - 524us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.2181 - accuracy: 0.9247 - 6ms/epoch - 561us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.2147 - accuracy: 0.9178 - 5ms/epoch - 514us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.2130 - accuracy: 0.9281 - 5ms/epoch - 523us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.2938 - accuracy: 0.8767 - 5ms/epoch - 539us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.2536 - accuracy: 0.8836 - 5ms/epoch - 529us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.2265 - accuracy: 0.9178 - 5ms/epoch - 514us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.2480 - accuracy: 0.9041 - 5ms/epoch - 543us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.2203 - accuracy: 0.9281 - 5ms/epoch - 533us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.2432 - accuracy: 0.9075 - 5ms/epoch - 527us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.2235 - accuracy: 0.9144 - 5ms/epoch - 532us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.2013 - accuracy: 0.9110 - 5ms/epoch - 508us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.2107 - accuracy: 0.9178 - 6ms/epoch - 558us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.2570 - accuracy: 0.9007 - 5ms/epoch - 513us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.2360 - accuracy: 0.9007 - 5ms/epoch - 528us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.2231 - accuracy: 0.9041 - 6ms/epoch - 559us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.2127 - accuracy: 0.9315 - 5ms/epoch - 543us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1685fa710>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a63aa239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2891 - accuracy: 0.8776 - 56ms/epoch - 14ms/step\n",
      "Loss: 0.2891065776348114, Accuracy: 0.8775510191917419\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c354761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
