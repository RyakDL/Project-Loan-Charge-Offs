{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b492e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764d6b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'observation_date', 'C&I_DELNQ', 'CCARD_CO',\n",
       "       'CCARD_DELNQ', 'CORP_DEBT_NET_WORTH', 'CORP_SAVINGS_LEVEL', 'CRE_CO',\n",
       "       'CRE_DELNQ', 'GDP', 'Homeowner_Vacancy_rate', 'Household_DBT_Inc',\n",
       "       'Mortgage_CO', 'Mortgage_DELNQ', 'Rental_Vacancy_Rate',\n",
       "       'Consumer_Confidence', 'FEDFUNDS', 'Manufacturing_Confidence',\n",
       "       'SAVINGS_RATE_MO', 'UNRATE', 'C&I_CO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DataFrame \n",
    "main_df = pd.read_csv('Rates_MO.csv')\n",
    "main_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33b87d",
   "metadata": {},
   "source": [
    "# Credit Cards Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc6061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create credit card dataset\n",
    "ccard_df = main_df[['observation_date', 'CCARD_CO', 'CCARD_DELNQ', 'GDP', 'Household_DBT_Inc', 'Consumer_Confidence', 'FEDFUNDS', 'SAVINGS_RATE_MO', 'UNRATE']]\n",
    " \n",
    "# Create copy for bins\n",
    "ccard_bin_df = ccard_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7424394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning the data for classification Question: \n",
    "ccard_bin_df[\"CCARD_CO_BIN\"] = pd.qcut(ccard_df['CCARD_CO'],4, labels= [1, 2, 3, 4])\n",
    "\n",
    "# Seperate the y and X variables\n",
    "y = ccard_bin_df[\"CCARD_CO_BIN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021509da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCARD_DELNQ</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Household_DBT_Inc</th>\n",
       "      <th>Consumer_Confidence</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>SAVINGS_RATE_MO</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.26</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>66.8</td>\n",
       "      <td>6.91</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.26</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>70.4</td>\n",
       "      <td>6.25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.26</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>87.7</td>\n",
       "      <td>6.12</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.48</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.434237</td>\n",
       "      <td>81.8</td>\n",
       "      <td>5.91</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.48</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.434237</td>\n",
       "      <td>78.3</td>\n",
       "      <td>5.78</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2.43</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.848832</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2.43</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.848832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2.77</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>63.5</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2.77</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>59.2</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2.77</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>64.4</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CCARD_DELNQ  GDP  Household_DBT_Inc  Consumer_Confidence  FEDFUNDS  \\\n",
       "0           5.26 -1.9          11.578032                 66.8      6.91   \n",
       "1           5.26 -1.9          11.578032                 70.4      6.25   \n",
       "2           5.26 -1.9          11.578032                 87.7      6.12   \n",
       "3           5.48  3.2          11.434237                 81.8      5.91   \n",
       "4           5.48  3.2          11.434237                 78.3      5.78   \n",
       "..           ...  ...                ...                  ...       ...   \n",
       "385         2.43  2.2           9.848832                 67.0      4.57   \n",
       "386         2.43  2.2           9.848832                 62.0      4.65   \n",
       "387         2.77  2.1           9.826692                 63.5      4.83   \n",
       "388         2.77  2.1           9.826692                 59.2      5.06   \n",
       "389         2.77  2.1           9.826692                 64.4      5.08   \n",
       "\n",
       "     SAVINGS_RATE_MO  UNRATE  \n",
       "0                9.4     6.4  \n",
       "1                9.0     6.6  \n",
       "2                8.1     6.8  \n",
       "3                8.7     6.7  \n",
       "4                8.5     6.9  \n",
       "..               ...     ...  \n",
       "385              4.7     3.6  \n",
       "386              5.2     3.5  \n",
       "387              5.2     3.4  \n",
       "388              5.3     3.7  \n",
       "389              4.9     3.6  \n",
       "\n",
       "[390 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccard_df = ccard_df.drop(columns=[\"CCARD_CO\",\"observation_date\"])\n",
    "ccard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c4f8d",
   "metadata": {},
   "source": [
    "# Deep Learning - Credit Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0dcb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ccard_df, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4033bb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ac2a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16858238 0.48089172 0.31664056 ... 0.65889213 0.10784314 0.01769912]\n",
      " [0.5210728  0.55414013 0.60881321 ... 0.75364431 0.13398693 0.19469027]\n",
      " [0.58429119 0.45700637 0.43389017 ... 0.44023324 0.24183007 0.31858407]\n",
      " ...\n",
      " [0.57471264 0.55254777 0.66558862 ... 0.75072886 0.08496732 0.0619469 ]\n",
      " [0.33333333 0.53343949 0.44074702 ... 0.57725948 0.19934641 0.23893805]\n",
      " [0.47318008 0.48566879 0.95252878 ... 0.75801749 0.04248366 0.10619469]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d881bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set shape:  (292, 7)\n",
      "y_train set shape:  (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train set shape: \", X_train_scaled.shape)\n",
    "print(\"y_train set shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d5892e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 2, 1, ..., 2, 1, 3, 1, 2]\n",
       "Length: 292\n",
       "Categories (4, int64): [1 < 2 < 3 < 4]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f18238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = to_categorical(y_train.values, num_classes)\n",
    "y_test = to_categorical(y_test.values, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "939bab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 205       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11385 (44.47 KB)\n",
      "Trainable params: 11385 (44.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layers1 = 60\n",
    "hidden_nodes_layers2 = 60\n",
    "hidden_nodes_layers3 = 60\n",
    "hidden_nodes_layers4 = 40\n",
    "\n",
    "\n",
    "model.add(Dense(20, activation='relu', input_dim=number_input_features))\n",
    "model.add(Dense(hidden_nodes_layers1, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers2, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers3, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers4, activation='relu'))\n",
    "# model.add(Dense(hidden_nodes_layers5, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e1aad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 1.5721 - accuracy: 0.4349 - 158ms/epoch - 16ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 1.5060 - accuracy: 0.4452 - 5ms/epoch - 470us/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 1.4312 - accuracy: 0.3082 - 4ms/epoch - 440us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.3320 - accuracy: 0.4212 - 4ms/epoch - 442us/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.2238 - accuracy: 0.5000 - 6ms/epoch - 573us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 1.1070 - accuracy: 0.6438 - 5ms/epoch - 497us/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 0.9886 - accuracy: 0.5959 - 5ms/epoch - 498us/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 0.9081 - accuracy: 0.6644 - 5ms/epoch - 502us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 0.8424 - accuracy: 0.6164 - 5ms/epoch - 537us/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.8036 - accuracy: 0.6712 - 5ms/epoch - 538us/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.7794 - accuracy: 0.6267 - 5ms/epoch - 526us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.7546 - accuracy: 0.6404 - 6ms/epoch - 587us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.7216 - accuracy: 0.6541 - 10ms/epoch - 985us/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.6955 - accuracy: 0.6644 - 7ms/epoch - 706us/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.6737 - accuracy: 0.6507 - 5ms/epoch - 550us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.6620 - accuracy: 0.7123 - 5ms/epoch - 523us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.6285 - accuracy: 0.6884 - 6ms/epoch - 591us/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.6261 - accuracy: 0.6747 - 5ms/epoch - 526us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.6138 - accuracy: 0.7603 - 6ms/epoch - 629us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.6723 - accuracy: 0.7021 - 5ms/epoch - 526us/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.5687 - accuracy: 0.7671 - 5ms/epoch - 514us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.5601 - accuracy: 0.7603 - 6ms/epoch - 574us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.5663 - accuracy: 0.7877 - 5ms/epoch - 533us/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.5469 - accuracy: 0.7534 - 6ms/epoch - 552us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.5238 - accuracy: 0.7911 - 5ms/epoch - 522us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.5068 - accuracy: 0.7979 - 5ms/epoch - 523us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.5017 - accuracy: 0.7637 - 6ms/epoch - 580us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.5254 - accuracy: 0.7740 - 5ms/epoch - 521us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.4672 - accuracy: 0.8151 - 5ms/epoch - 522us/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.4619 - accuracy: 0.8288 - 6ms/epoch - 609us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.4880 - accuracy: 0.8082 - 6ms/epoch - 550us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.4574 - accuracy: 0.8116 - 6ms/epoch - 563us/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.4525 - accuracy: 0.8253 - 5ms/epoch - 535us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.4474 - accuracy: 0.8082 - 5ms/epoch - 528us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.5014 - accuracy: 0.7740 - 6ms/epoch - 604us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.5045 - accuracy: 0.7945 - 5ms/epoch - 545us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.4335 - accuracy: 0.8219 - 5ms/epoch - 544us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.4571 - accuracy: 0.8048 - 6ms/epoch - 572us/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.4225 - accuracy: 0.8356 - 6ms/epoch - 566us/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.4448 - accuracy: 0.8082 - 6ms/epoch - 577us/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.4105 - accuracy: 0.8219 - 5ms/epoch - 539us/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.4065 - accuracy: 0.8459 - 5ms/epoch - 545us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.4408 - accuracy: 0.8493 - 6ms/epoch - 588us/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.4274 - accuracy: 0.8219 - 5ms/epoch - 519us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.4156 - accuracy: 0.8082 - 5ms/epoch - 535us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.4273 - accuracy: 0.8116 - 6ms/epoch - 569us/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.3908 - accuracy: 0.8527 - 5ms/epoch - 535us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.3920 - accuracy: 0.8322 - 5ms/epoch - 542us/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.3758 - accuracy: 0.8562 - 6ms/epoch - 583us/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.3726 - accuracy: 0.8390 - 5ms/epoch - 536us/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.4123 - accuracy: 0.8082 - 6ms/epoch - 597us/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.3934 - accuracy: 0.8322 - 5ms/epoch - 541us/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.4821 - accuracy: 0.7877 - 5ms/epoch - 510us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.4431 - accuracy: 0.8116 - 6ms/epoch - 584us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.4071 - accuracy: 0.8288 - 5ms/epoch - 536us/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.3902 - accuracy: 0.8562 - 5ms/epoch - 541us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.4203 - accuracy: 0.8288 - 6ms/epoch - 606us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.3846 - accuracy: 0.8527 - 6ms/epoch - 553us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.3605 - accuracy: 0.8425 - 5ms/epoch - 536us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.3925 - accuracy: 0.8527 - 5ms/epoch - 535us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.3800 - accuracy: 0.8459 - 5ms/epoch - 536us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.3681 - accuracy: 0.8527 - 5ms/epoch - 515us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.3523 - accuracy: 0.8630 - 5ms/epoch - 523us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.3914 - accuracy: 0.8356 - 5ms/epoch - 514us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.4202 - accuracy: 0.8288 - 5ms/epoch - 517us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.3742 - accuracy: 0.8356 - 5ms/epoch - 513us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.3406 - accuracy: 0.8733 - 5ms/epoch - 546us/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.3586 - accuracy: 0.8459 - 5ms/epoch - 509us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.3423 - accuracy: 0.8562 - 5ms/epoch - 548us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.3318 - accuracy: 0.8733 - 5ms/epoch - 507us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.3332 - accuracy: 0.8562 - 5ms/epoch - 510us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.3483 - accuracy: 0.8527 - 5ms/epoch - 519us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.3373 - accuracy: 0.8699 - 5ms/epoch - 535us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.3493 - accuracy: 0.8562 - 5ms/epoch - 517us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.3430 - accuracy: 0.8493 - 5ms/epoch - 515us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.4002 - accuracy: 0.8459 - 5ms/epoch - 546us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.3823 - accuracy: 0.8459 - 5ms/epoch - 520us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.3552 - accuracy: 0.8356 - 5ms/epoch - 520us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.3328 - accuracy: 0.8733 - 5ms/epoch - 520us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.3367 - accuracy: 0.8733 - 5ms/epoch - 512us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.3293 - accuracy: 0.8664 - 5ms/epoch - 513us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.4149 - accuracy: 0.8219 - 6ms/epoch - 556us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.3415 - accuracy: 0.8493 - 5ms/epoch - 528us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.3641 - accuracy: 0.8562 - 5ms/epoch - 539us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.3189 - accuracy: 0.8801 - 5ms/epoch - 522us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.3132 - accuracy: 0.8836 - 5ms/epoch - 496us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.3125 - accuracy: 0.9007 - 5ms/epoch - 546us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.2945 - accuracy: 0.8801 - 5ms/epoch - 524us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.3323 - accuracy: 0.8664 - 5ms/epoch - 529us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.3263 - accuracy: 0.8733 - 5ms/epoch - 526us/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.2988 - accuracy: 0.8836 - 5ms/epoch - 513us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.3122 - accuracy: 0.8630 - 5ms/epoch - 525us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.2932 - accuracy: 0.8973 - 6ms/epoch - 557us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.3018 - accuracy: 0.8904 - 5ms/epoch - 514us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.3099 - accuracy: 0.8870 - 5ms/epoch - 540us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.2944 - accuracy: 0.8870 - 5ms/epoch - 534us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.3044 - accuracy: 0.8733 - 5ms/epoch - 531us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.3160 - accuracy: 0.8801 - 5ms/epoch - 513us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.2814 - accuracy: 0.8870 - 5ms/epoch - 529us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.2911 - accuracy: 0.8904 - 5ms/epoch - 503us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.2813 - accuracy: 0.8870 - 5ms/epoch - 502us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.3113 - accuracy: 0.8527 - 5ms/epoch - 514us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.2829 - accuracy: 0.8870 - 5ms/epoch - 516us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.3144 - accuracy: 0.8767 - 5ms/epoch - 518us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.3003 - accuracy: 0.8699 - 5ms/epoch - 532us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.3710 - accuracy: 0.8459 - 5ms/epoch - 523us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.3387 - accuracy: 0.8699 - 5ms/epoch - 516us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.3081 - accuracy: 0.8733 - 5ms/epoch - 492us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.3464 - accuracy: 0.8322 - 5ms/epoch - 510us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.3336 - accuracy: 0.8562 - 6ms/epoch - 551us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.3161 - accuracy: 0.8562 - 5ms/epoch - 520us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.3234 - accuracy: 0.8870 - 5ms/epoch - 514us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.2815 - accuracy: 0.8973 - 5ms/epoch - 511us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.2959 - accuracy: 0.8870 - 5ms/epoch - 522us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.2796 - accuracy: 0.8973 - 5ms/epoch - 540us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.2951 - accuracy: 0.9041 - 5ms/epoch - 518us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.2635 - accuracy: 0.8938 - 5ms/epoch - 516us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.2817 - accuracy: 0.8973 - 5ms/epoch - 529us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.2886 - accuracy: 0.8836 - 5ms/epoch - 520us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.2781 - accuracy: 0.8870 - 5ms/epoch - 519us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.2800 - accuracy: 0.8973 - 5ms/epoch - 509us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.2568 - accuracy: 0.8973 - 5ms/epoch - 486us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.2844 - accuracy: 0.8870 - 6ms/epoch - 551us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.2692 - accuracy: 0.9007 - 5ms/epoch - 534us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.2763 - accuracy: 0.8870 - 5ms/epoch - 530us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.2799 - accuracy: 0.8836 - 5ms/epoch - 497us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.2754 - accuracy: 0.8767 - 5ms/epoch - 542us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.2796 - accuracy: 0.8836 - 5ms/epoch - 530us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.4288 - accuracy: 0.8253 - 5ms/epoch - 520us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.3166 - accuracy: 0.8904 - 5ms/epoch - 538us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.3115 - accuracy: 0.8699 - 5ms/epoch - 524us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.2938 - accuracy: 0.8699 - 5ms/epoch - 520us/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.2629 - accuracy: 0.8904 - 5ms/epoch - 538us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.2575 - accuracy: 0.8973 - 5ms/epoch - 540us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.2548 - accuracy: 0.9041 - 5ms/epoch - 549us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.2506 - accuracy: 0.9007 - 5ms/epoch - 516us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.2497 - accuracy: 0.9178 - 5ms/epoch - 530us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.2431 - accuracy: 0.8973 - 6ms/epoch - 561us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.2513 - accuracy: 0.9041 - 5ms/epoch - 530us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.2460 - accuracy: 0.8973 - 5ms/epoch - 507us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.2393 - accuracy: 0.9110 - 5ms/epoch - 517us/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.2709 - accuracy: 0.9007 - 5ms/epoch - 526us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.3593 - accuracy: 0.8596 - 5ms/epoch - 516us/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.3260 - accuracy: 0.8664 - 5ms/epoch - 521us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.2795 - accuracy: 0.8938 - 5ms/epoch - 509us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.2673 - accuracy: 0.8938 - 5ms/epoch - 498us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.2585 - accuracy: 0.9007 - 5ms/epoch - 516us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.2387 - accuracy: 0.9075 - 5ms/epoch - 531us/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.2364 - accuracy: 0.9075 - 5ms/epoch - 521us/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.2420 - accuracy: 0.9110 - 5ms/epoch - 531us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.2642 - accuracy: 0.9007 - 5ms/epoch - 503us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.2464 - accuracy: 0.9041 - 5ms/epoch - 508us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.2290 - accuracy: 0.9247 - 5ms/epoch - 526us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.2272 - accuracy: 0.9075 - 5ms/epoch - 535us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.2795 - accuracy: 0.8767 - 5ms/epoch - 520us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.2513 - accuracy: 0.8973 - 5ms/epoch - 525us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.3370 - accuracy: 0.8801 - 5ms/epoch - 494us/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.4125 - accuracy: 0.8219 - 5ms/epoch - 527us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.3063 - accuracy: 0.8664 - 5ms/epoch - 522us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.2285 - accuracy: 0.9007 - 5ms/epoch - 511us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.2662 - accuracy: 0.8938 - 5ms/epoch - 523us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.2444 - accuracy: 0.9247 - 5ms/epoch - 513us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.3102 - accuracy: 0.8699 - 5ms/epoch - 504us/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.2388 - accuracy: 0.9041 - 5ms/epoch - 518us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.2358 - accuracy: 0.9075 - 5ms/epoch - 534us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.2526 - accuracy: 0.8973 - 5ms/epoch - 509us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.2536 - accuracy: 0.9075 - 5ms/epoch - 538us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.2354 - accuracy: 0.9007 - 6ms/epoch - 556us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.2237 - accuracy: 0.9212 - 8ms/epoch - 777us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.2110 - accuracy: 0.9178 - 6ms/epoch - 553us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.2161 - accuracy: 0.9178 - 6ms/epoch - 568us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.2145 - accuracy: 0.9178 - 7ms/epoch - 657us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.2172 - accuracy: 0.9144 - 5ms/epoch - 541us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.2108 - accuracy: 0.9281 - 6ms/epoch - 555us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.2033 - accuracy: 0.9178 - 7ms/epoch - 663us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.2166 - accuracy: 0.9281 - 5ms/epoch - 538us/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.2010 - accuracy: 0.9144 - 7ms/epoch - 662us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.1931 - accuracy: 0.9384 - 6ms/epoch - 575us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.2416 - accuracy: 0.9110 - 5ms/epoch - 549us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.2333 - accuracy: 0.9178 - 6ms/epoch - 556us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.2337 - accuracy: 0.9144 - 5ms/epoch - 504us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.2235 - accuracy: 0.9178 - 6ms/epoch - 567us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.2216 - accuracy: 0.9144 - 6ms/epoch - 566us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.2088 - accuracy: 0.9247 - 5ms/epoch - 520us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.1986 - accuracy: 0.9315 - 6ms/epoch - 563us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.2153 - accuracy: 0.9110 - 8ms/epoch - 837us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.1904 - accuracy: 0.9315 - 6ms/epoch - 617us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.1858 - accuracy: 0.9281 - 5ms/epoch - 502us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.2285 - accuracy: 0.8973 - 5ms/epoch - 527us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.1884 - accuracy: 0.9212 - 6ms/epoch - 572us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.1839 - accuracy: 0.9418 - 5ms/epoch - 522us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.2063 - accuracy: 0.9144 - 6ms/epoch - 583us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.1926 - accuracy: 0.9521 - 6ms/epoch - 558us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.2150 - accuracy: 0.9110 - 5ms/epoch - 524us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.2223 - accuracy: 0.9247 - 6ms/epoch - 577us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.2034 - accuracy: 0.9178 - 5ms/epoch - 514us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.1841 - accuracy: 0.9384 - 5ms/epoch - 516us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.1748 - accuracy: 0.9452 - 6ms/epoch - 628us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.1982 - accuracy: 0.9178 - 6ms/epoch - 616us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.2042 - accuracy: 0.9418 - 7ms/epoch - 687us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x282bfa320>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "335f4ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3067 - accuracy: 0.9082 - 63ms/epoch - 16ms/step\n",
      "Loss: 0.30674079060554504, Accuracy: 0.9081632494926453\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eeec33",
   "metadata": {},
   "source": [
    "# Mortgage Loan Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4317358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observation_date', 'Mortgage_CO', 'Mortgage_DELNQ', 'GDP',\n",
       "       'Household_DBT_Inc', 'Consumer_Confidence', 'FEDFUNDS',\n",
       "       'SAVINGS_RATE_MO', 'UNRATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mortgage loan dataset\n",
    "mort_df = main_df[['observation_date', 'Mortgage_CO', 'Mortgage_DELNQ', 'GDP', 'Household_DBT_Inc', 'Consumer_Confidence', 'FEDFUNDS', 'SAVINGS_RATE_MO', 'UNRATE']]\n",
    "\n",
    "mort_bin_df = mort_df.copy()\n",
    "\n",
    "mort_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1787ee06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mortgage_DELNQ</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Household_DBT_Inc</th>\n",
       "      <th>Consumer_Confidence</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>SAVINGS_RATE_MO</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.09</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>66.8</td>\n",
       "      <td>6.91</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.09</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>70.4</td>\n",
       "      <td>6.25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.09</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>11.578032</td>\n",
       "      <td>87.7</td>\n",
       "      <td>6.12</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.18</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.434237</td>\n",
       "      <td>81.8</td>\n",
       "      <td>5.91</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.18</td>\n",
       "      <td>3.2</td>\n",
       "      <td>11.434237</td>\n",
       "      <td>78.3</td>\n",
       "      <td>5.78</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1.74</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.848832</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1.74</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.848832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1.72</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>63.5</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1.72</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>59.2</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1.72</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.826692</td>\n",
       "      <td>64.4</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mortgage_DELNQ  GDP  Household_DBT_Inc  Consumer_Confidence  FEDFUNDS  \\\n",
       "0              3.09 -1.9          11.578032                 66.8      6.91   \n",
       "1              3.09 -1.9          11.578032                 70.4      6.25   \n",
       "2              3.09 -1.9          11.578032                 87.7      6.12   \n",
       "3              3.18  3.2          11.434237                 81.8      5.91   \n",
       "4              3.18  3.2          11.434237                 78.3      5.78   \n",
       "..              ...  ...                ...                  ...       ...   \n",
       "385            1.74  2.2           9.848832                 67.0      4.57   \n",
       "386            1.74  2.2           9.848832                 62.0      4.65   \n",
       "387            1.72  2.1           9.826692                 63.5      4.83   \n",
       "388            1.72  2.1           9.826692                 59.2      5.06   \n",
       "389            1.72  2.1           9.826692                 64.4      5.08   \n",
       "\n",
       "     SAVINGS_RATE_MO  UNRATE  \n",
       "0                9.4     6.4  \n",
       "1                9.0     6.6  \n",
       "2                8.1     6.8  \n",
       "3                8.7     6.7  \n",
       "4                8.5     6.9  \n",
       "..               ...     ...  \n",
       "385              4.7     3.6  \n",
       "386              5.2     3.5  \n",
       "387              5.2     3.4  \n",
       "388              5.3     3.7  \n",
       "389              4.9     3.6  \n",
       "\n",
       "[390 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binning the data for classification Question: \n",
    "mort_bin_df[\"Mortgage_CO_BIN\"] = pd.qcut(mort_df['Mortgage_CO'],4, labels= [1, 2, 3, 4])\n",
    "# Define the dependent Y variable\n",
    "y = mort_bin_df[\"Mortgage_CO_BIN\"]\n",
    "mort_df = mort_df.drop(columns=['Mortgage_CO','observation_date'])\n",
    "mort_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b2282",
   "metadata": {},
   "source": [
    "# Deep Learning: Mortgage Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b1a82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ccard_df, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa98fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03b8158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set shape:  (292, 7)\n",
      "y_train set shape:  (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train set shape: \", X_train_scaled.shape)\n",
    "print(\"y_train set shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74552de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 3, 4, ..., 2, 1, 2, 3, 3]\n",
       "Length: 292\n",
       "Categories (4, int64): [1 < 2 < 3 < 4]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c8e2ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = to_categorical(y_train.values, num_classes)\n",
    "y_test = to_categorical(y_test.values, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ae91dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 205       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11385 (44.47 KB)\n",
      "Trainable params: 11385 (44.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layers1 = 60\n",
    "hidden_nodes_layers2 = 60\n",
    "hidden_nodes_layers3 = 60\n",
    "hidden_nodes_layers4 = 40\n",
    "\n",
    "\n",
    "model.add(Dense(20, activation='relu', input_dim=number_input_features))\n",
    "model.add(Dense(hidden_nodes_layers1, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers2, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers3, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers4, activation='relu'))\n",
    "# model.add(Dense(hidden_nodes_layers5, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f299af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 1.5899 - accuracy: 0.2877 - 133ms/epoch - 13ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 1.5493 - accuracy: 0.2808 - 6ms/epoch - 575us/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 1.4974 - accuracy: 0.2808 - 5ms/epoch - 460us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.4274 - accuracy: 0.2842 - 5ms/epoch - 468us/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.3511 - accuracy: 0.3733 - 6ms/epoch - 558us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 1.2602 - accuracy: 0.4829 - 5ms/epoch - 499us/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 1.1629 - accuracy: 0.5479 - 5ms/epoch - 475us/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 1.0401 - accuracy: 0.6164 - 6ms/epoch - 557us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 0.9525 - accuracy: 0.6267 - 5ms/epoch - 488us/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.9264 - accuracy: 0.6062 - 5ms/epoch - 517us/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.8761 - accuracy: 0.6849 - 6ms/epoch - 584us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.8502 - accuracy: 0.6473 - 5ms/epoch - 505us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.8029 - accuracy: 0.6781 - 5ms/epoch - 523us/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.7920 - accuracy: 0.6781 - 6ms/epoch - 566us/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.7477 - accuracy: 0.6952 - 5ms/epoch - 530us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.7188 - accuracy: 0.7158 - 6ms/epoch - 558us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.7011 - accuracy: 0.7158 - 5ms/epoch - 548us/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.7246 - accuracy: 0.7329 - 5ms/epoch - 512us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.6987 - accuracy: 0.7192 - 6ms/epoch - 580us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.6845 - accuracy: 0.7329 - 6ms/epoch - 552us/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.6629 - accuracy: 0.7089 - 5ms/epoch - 512us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.6444 - accuracy: 0.7295 - 6ms/epoch - 553us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.6404 - accuracy: 0.7260 - 5ms/epoch - 518us/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.6408 - accuracy: 0.7089 - 6ms/epoch - 565us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.6027 - accuracy: 0.7500 - 5ms/epoch - 541us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.5816 - accuracy: 0.7534 - 5ms/epoch - 542us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.5838 - accuracy: 0.7123 - 7ms/epoch - 710us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.6329 - accuracy: 0.7397 - 6ms/epoch - 632us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.6296 - accuracy: 0.7260 - 6ms/epoch - 553us/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.5845 - accuracy: 0.7534 - 7ms/epoch - 652us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.5767 - accuracy: 0.7466 - 5ms/epoch - 534us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.5322 - accuracy: 0.7877 - 7ms/epoch - 660us/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.5119 - accuracy: 0.7911 - 5ms/epoch - 514us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.5065 - accuracy: 0.7671 - 6ms/epoch - 552us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.4854 - accuracy: 0.7945 - 6ms/epoch - 574us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.4901 - accuracy: 0.7911 - 5ms/epoch - 509us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.5013 - accuracy: 0.7808 - 6ms/epoch - 607us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.5028 - accuracy: 0.7671 - 5ms/epoch - 534us/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.5055 - accuracy: 0.7671 - 5ms/epoch - 484us/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.4664 - accuracy: 0.8048 - 6ms/epoch - 596us/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.4864 - accuracy: 0.7979 - 6ms/epoch - 557us/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.4488 - accuracy: 0.8116 - 5ms/epoch - 512us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.4413 - accuracy: 0.8082 - 5ms/epoch - 529us/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.4557 - accuracy: 0.7911 - 5ms/epoch - 508us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.4272 - accuracy: 0.8185 - 5ms/epoch - 545us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.4176 - accuracy: 0.8322 - 6ms/epoch - 608us/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.4273 - accuracy: 0.8288 - 5ms/epoch - 482us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.4105 - accuracy: 0.8288 - 6ms/epoch - 576us/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.4250 - accuracy: 0.8116 - 5ms/epoch - 533us/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.4413 - accuracy: 0.8116 - 5ms/epoch - 517us/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.4234 - accuracy: 0.8219 - 6ms/epoch - 610us/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.4272 - accuracy: 0.8253 - 5ms/epoch - 521us/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.4290 - accuracy: 0.8014 - 5ms/epoch - 546us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.4455 - accuracy: 0.8014 - 6ms/epoch - 618us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.4445 - accuracy: 0.8048 - 5ms/epoch - 491us/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.3947 - accuracy: 0.8082 - 5ms/epoch - 545us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.4123 - accuracy: 0.8390 - 6ms/epoch - 554us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.4116 - accuracy: 0.8288 - 5ms/epoch - 501us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.3968 - accuracy: 0.8699 - 6ms/epoch - 589us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.3958 - accuracy: 0.8356 - 5ms/epoch - 510us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.3822 - accuracy: 0.8493 - 5ms/epoch - 494us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.3779 - accuracy: 0.8322 - 6ms/epoch - 596us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.3976 - accuracy: 0.8425 - 5ms/epoch - 498us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.3644 - accuracy: 0.8630 - 5ms/epoch - 518us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.3484 - accuracy: 0.8699 - 6ms/epoch - 637us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.3470 - accuracy: 0.8630 - 5ms/epoch - 497us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.3502 - accuracy: 0.8801 - 6ms/epoch - 564us/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.3425 - accuracy: 0.8596 - 6ms/epoch - 617us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.3346 - accuracy: 0.8836 - 5ms/epoch - 523us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.3586 - accuracy: 0.8630 - 6ms/epoch - 606us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.3296 - accuracy: 0.8938 - 6ms/epoch - 622us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.3284 - accuracy: 0.8836 - 6ms/epoch - 575us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.3278 - accuracy: 0.8733 - 6ms/epoch - 608us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.3208 - accuracy: 0.8904 - 5ms/epoch - 527us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.3190 - accuracy: 0.8664 - 5ms/epoch - 544us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.3287 - accuracy: 0.8733 - 5ms/epoch - 519us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.3410 - accuracy: 0.8733 - 5ms/epoch - 511us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.3368 - accuracy: 0.8699 - 5ms/epoch - 523us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.4218 - accuracy: 0.8288 - 5ms/epoch - 531us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.3357 - accuracy: 0.8664 - 5ms/epoch - 529us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.3078 - accuracy: 0.9007 - 6ms/epoch - 558us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.3105 - accuracy: 0.8801 - 5ms/epoch - 521us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.3309 - accuracy: 0.8699 - 5ms/epoch - 523us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.3251 - accuracy: 0.8699 - 5ms/epoch - 542us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.3400 - accuracy: 0.8493 - 5ms/epoch - 509us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.3118 - accuracy: 0.8767 - 5ms/epoch - 532us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.2895 - accuracy: 0.8836 - 5ms/epoch - 532us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.2869 - accuracy: 0.8904 - 5ms/epoch - 525us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.3151 - accuracy: 0.8973 - 5ms/epoch - 538us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.2993 - accuracy: 0.8664 - 5ms/epoch - 502us/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.3311 - accuracy: 0.8767 - 5ms/epoch - 514us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.3219 - accuracy: 0.8733 - 6ms/epoch - 579us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.3018 - accuracy: 0.8904 - 5ms/epoch - 525us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.3186 - accuracy: 0.8664 - 5ms/epoch - 502us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.3086 - accuracy: 0.8767 - 8ms/epoch - 848us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.2830 - accuracy: 0.8973 - 6ms/epoch - 647us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.2829 - accuracy: 0.8938 - 5ms/epoch - 536us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.2652 - accuracy: 0.8973 - 5ms/epoch - 525us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.2687 - accuracy: 0.8973 - 5ms/epoch - 508us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.3076 - accuracy: 0.8699 - 5ms/epoch - 536us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.2902 - accuracy: 0.8870 - 5ms/epoch - 527us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.2620 - accuracy: 0.9247 - 5ms/epoch - 514us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.2894 - accuracy: 0.9007 - 5ms/epoch - 513us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.3818 - accuracy: 0.8390 - 5ms/epoch - 526us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.4070 - accuracy: 0.8219 - 5ms/epoch - 526us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.3181 - accuracy: 0.8870 - 5ms/epoch - 518us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.2682 - accuracy: 0.9075 - 5ms/epoch - 511us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.2748 - accuracy: 0.8904 - 5ms/epoch - 544us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.2531 - accuracy: 0.9110 - 5ms/epoch - 525us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.2586 - accuracy: 0.8904 - 5ms/epoch - 502us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.2759 - accuracy: 0.8870 - 5ms/epoch - 537us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.2590 - accuracy: 0.9178 - 5ms/epoch - 528us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.3187 - accuracy: 0.8630 - 5ms/epoch - 534us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.2639 - accuracy: 0.8973 - 5ms/epoch - 545us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.2773 - accuracy: 0.8767 - 5ms/epoch - 509us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.2869 - accuracy: 0.8904 - 5ms/epoch - 520us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.3575 - accuracy: 0.8699 - 5ms/epoch - 550us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.2924 - accuracy: 0.8836 - 5ms/epoch - 534us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.2817 - accuracy: 0.8870 - 5ms/epoch - 527us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.2479 - accuracy: 0.8973 - 5ms/epoch - 521us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.2602 - accuracy: 0.8904 - 5ms/epoch - 525us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.2462 - accuracy: 0.9007 - 5ms/epoch - 531us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.2406 - accuracy: 0.8973 - 5ms/epoch - 516us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.2459 - accuracy: 0.9178 - 5ms/epoch - 518us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.2388 - accuracy: 0.9075 - 6ms/epoch - 566us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.2895 - accuracy: 0.8767 - 5ms/epoch - 536us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.2572 - accuracy: 0.8870 - 6ms/epoch - 618us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.2567 - accuracy: 0.8904 - 6ms/epoch - 568us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.2277 - accuracy: 0.9075 - 5ms/epoch - 530us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.2512 - accuracy: 0.9007 - 5ms/epoch - 530us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.2527 - accuracy: 0.9007 - 6ms/epoch - 556us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.2304 - accuracy: 0.9075 - 5ms/epoch - 527us/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.2210 - accuracy: 0.9041 - 6ms/epoch - 557us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.2187 - accuracy: 0.9212 - 5ms/epoch - 541us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.2167 - accuracy: 0.9144 - 5ms/epoch - 520us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.2386 - accuracy: 0.9007 - 6ms/epoch - 555us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.2285 - accuracy: 0.8973 - 5ms/epoch - 522us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.2361 - accuracy: 0.9041 - 5ms/epoch - 514us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.2191 - accuracy: 0.9075 - 5ms/epoch - 529us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.2629 - accuracy: 0.8801 - 5ms/epoch - 529us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.2614 - accuracy: 0.8767 - 6ms/epoch - 575us/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.2245 - accuracy: 0.9178 - 6ms/epoch - 559us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.2463 - accuracy: 0.8904 - 5ms/epoch - 530us/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.2282 - accuracy: 0.8938 - 5ms/epoch - 536us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.2278 - accuracy: 0.9075 - 5ms/epoch - 536us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.2420 - accuracy: 0.8938 - 6ms/epoch - 551us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.2468 - accuracy: 0.8870 - 5ms/epoch - 531us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.2236 - accuracy: 0.9144 - 5ms/epoch - 520us/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.2080 - accuracy: 0.9110 - 5ms/epoch - 512us/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.2070 - accuracy: 0.9041 - 5ms/epoch - 548us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.2067 - accuracy: 0.9144 - 5ms/epoch - 536us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.2094 - accuracy: 0.8973 - 5ms/epoch - 510us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.2325 - accuracy: 0.9110 - 6ms/epoch - 551us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.2075 - accuracy: 0.9075 - 5ms/epoch - 518us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.2194 - accuracy: 0.9144 - 5ms/epoch - 539us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.2805 - accuracy: 0.8699 - 5ms/epoch - 542us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.2052 - accuracy: 0.9178 - 5ms/epoch - 508us/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.2154 - accuracy: 0.9110 - 5ms/epoch - 520us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.2061 - accuracy: 0.9144 - 5ms/epoch - 534us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.1924 - accuracy: 0.9212 - 5ms/epoch - 520us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.1842 - accuracy: 0.9247 - 5ms/epoch - 540us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.1899 - accuracy: 0.9110 - 5ms/epoch - 519us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.1876 - accuracy: 0.9178 - 5ms/epoch - 502us/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.2028 - accuracy: 0.9075 - 5ms/epoch - 518us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.1831 - accuracy: 0.9178 - 5ms/epoch - 533us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.1853 - accuracy: 0.9178 - 5ms/epoch - 508us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.4808 - accuracy: 0.8425 - 5ms/epoch - 543us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.3101 - accuracy: 0.8733 - 5ms/epoch - 510us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.2503 - accuracy: 0.9041 - 5ms/epoch - 533us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.2585 - accuracy: 0.8938 - 5ms/epoch - 546us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.2478 - accuracy: 0.8938 - 5ms/epoch - 513us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.1958 - accuracy: 0.9144 - 5ms/epoch - 524us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.1967 - accuracy: 0.9144 - 5ms/epoch - 548us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.2007 - accuracy: 0.8938 - 5ms/epoch - 520us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.2052 - accuracy: 0.9144 - 6ms/epoch - 564us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.1980 - accuracy: 0.9144 - 5ms/epoch - 539us/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.1868 - accuracy: 0.9144 - 5ms/epoch - 525us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.2245 - accuracy: 0.9110 - 5ms/epoch - 530us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.2021 - accuracy: 0.9110 - 5ms/epoch - 512us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.1808 - accuracy: 0.9281 - 5ms/epoch - 517us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.1780 - accuracy: 0.9247 - 5ms/epoch - 534us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.1812 - accuracy: 0.9144 - 5ms/epoch - 517us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.2156 - accuracy: 0.9075 - 5ms/epoch - 512us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.1976 - accuracy: 0.9041 - 5ms/epoch - 523us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.1682 - accuracy: 0.9144 - 5ms/epoch - 526us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.1848 - accuracy: 0.9349 - 5ms/epoch - 523us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.2347 - accuracy: 0.9144 - 5ms/epoch - 539us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.1842 - accuracy: 0.9144 - 5ms/epoch - 514us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.2913 - accuracy: 0.8870 - 5ms/epoch - 505us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.2439 - accuracy: 0.8904 - 5ms/epoch - 548us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.2232 - accuracy: 0.9110 - 5ms/epoch - 526us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.2077 - accuracy: 0.9110 - 5ms/epoch - 520us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.1807 - accuracy: 0.9144 - 5ms/epoch - 523us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.1736 - accuracy: 0.9178 - 5ms/epoch - 517us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.1686 - accuracy: 0.9315 - 5ms/epoch - 530us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.1740 - accuracy: 0.9281 - 5ms/epoch - 538us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.1928 - accuracy: 0.9110 - 5ms/epoch - 533us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.1904 - accuracy: 0.9144 - 6ms/epoch - 556us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.1722 - accuracy: 0.9247 - 5ms/epoch - 520us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.1838 - accuracy: 0.9212 - 5ms/epoch - 515us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2837efac0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47502214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3752 - accuracy: 0.8878 - 43ms/epoch - 11ms/step\n",
      "Loss: 0.3752179443836212, Accuracy: 0.8877550959587097\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e14cf",
   "metadata": {},
   "source": [
    "# C&I Loan Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a02310c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observation_date', 'C&I_CO', 'C&I_DELNQ', 'GDP', 'CORP_DEBT_NET_WORTH',\n",
       "       'Manufacturing_Confidence', 'FEDFUNDS', 'CORP_SAVINGS_LEVEL', 'UNRATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create C&I loan dataset\n",
    "CI_df = main_df[['observation_date', 'C&I_CO', 'C&I_DELNQ', 'GDP', 'CORP_DEBT_NET_WORTH', 'Manufacturing_Confidence', 'FEDFUNDS', 'CORP_SAVINGS_LEVEL', 'UNRATE']]\n",
    "\n",
    "CI_bin_df = mort_df.copy()\n",
    "\n",
    "CI_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d088b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C&amp;I_DELNQ</th>\n",
       "      <th>GDP</th>\n",
       "      <th>CORP_DEBT_NET_WORTH</th>\n",
       "      <th>Manufacturing_Confidence</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>CORP_SAVINGS_LEVEL</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.29</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>96.951745</td>\n",
       "      <td>6.91</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.29</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>96.972896</td>\n",
       "      <td>6.25</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.29</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>97.223425</td>\n",
       "      <td>6.12</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>46.289579</td>\n",
       "      <td>97.678049</td>\n",
       "      <td>5.91</td>\n",
       "      <td>81.294</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>46.289579</td>\n",
       "      <td>98.292261</td>\n",
       "      <td>5.78</td>\n",
       "      <td>81.294</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.98</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.497128</td>\n",
       "      <td>98.951152</td>\n",
       "      <td>4.57</td>\n",
       "      <td>263.194</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.98</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.497128</td>\n",
       "      <td>98.913862</td>\n",
       "      <td>4.65</td>\n",
       "      <td>263.194</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1.01</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.904602</td>\n",
       "      <td>4.83</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1.01</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.887364</td>\n",
       "      <td>5.06</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1.01</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.872005</td>\n",
       "      <td>5.08</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C&I_DELNQ  GDP  CORP_DEBT_NET_WORTH  Manufacturing_Confidence  FEDFUNDS  \\\n",
       "0         6.29 -1.9            46.132964                 96.951745      6.91   \n",
       "1         6.29 -1.9            46.132964                 96.972896      6.25   \n",
       "2         6.29 -1.9            46.132964                 97.223425      6.12   \n",
       "3         6.41  3.2            46.289579                 97.678049      5.91   \n",
       "4         6.41  3.2            46.289579                 98.292261      5.78   \n",
       "..         ...  ...                  ...                       ...       ...   \n",
       "385       0.98  2.2            40.497128                 98.951152      4.57   \n",
       "386       0.98  2.2            40.497128                 98.913862      4.65   \n",
       "387       1.01  2.1            39.659559                 98.904602      4.83   \n",
       "388       1.01  2.1            39.659559                 98.887364      5.06   \n",
       "389       1.01  2.1            39.659559                 98.872005      5.08   \n",
       "\n",
       "     CORP_SAVINGS_LEVEL  UNRATE  \n",
       "0                77.964     6.4  \n",
       "1                77.964     6.6  \n",
       "2                77.964     6.8  \n",
       "3                81.294     6.7  \n",
       "4                81.294     6.9  \n",
       "..                  ...     ...  \n",
       "385             263.194     3.6  \n",
       "386             263.194     3.5  \n",
       "387             367.036     3.4  \n",
       "388             367.036     3.7  \n",
       "389             367.036     3.6  \n",
       "\n",
       "[390 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binning the data for classification Question: \n",
    "CI_bin_df[\"C&I_CO_BIN\"] = pd.qcut(CI_df['C&I_CO'],4, labels= [1, 2, 3, 4])\n",
    "\n",
    "# Define the dependent Y variable\n",
    "y = CI_bin_df[\"C&I_CO_BIN\"]\n",
    "\n",
    "CI_df = CI_df.drop(columns=['C&I_CO','observation_date'])\n",
    "CI_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d70353",
   "metadata": {},
   "source": [
    "# Deep Learning: C&I Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b0fb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ccard_df, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5db19197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ab3ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set shape:  (292, 7)\n",
      "y_train set shape:  (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train set shape: \", X_train_scaled.shape)\n",
    "print(\"y_train set shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c1f32aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 2, 1, ..., 1, 2, 3, 2, 3]\n",
       "Length: 292\n",
       "Categories (4, int64): [1 < 2 < 3 < 4]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7967441e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = to_categorical(y_train.values, num_classes)\n",
    "y_test = to_categorical(y_test.values, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdcf7f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 205       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11385 (44.47 KB)\n",
      "Trainable params: 11385 (44.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layers1 = 60\n",
    "hidden_nodes_layers2 = 60\n",
    "hidden_nodes_layers3 = 60\n",
    "hidden_nodes_layers4 = 40\n",
    "\n",
    "\n",
    "model.add(Dense(20, activation='relu', input_dim=number_input_features))\n",
    "model.add(Dense(hidden_nodes_layers1, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers2, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers3, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers4, activation='relu'))\n",
    "# model.add(Dense(hidden_nodes_layers5, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "591ca2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 1.5830 - accuracy: 0.3973 - 129ms/epoch - 13ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 1.5315 - accuracy: 0.3836 - 5ms/epoch - 512us/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 1.4629 - accuracy: 0.3733 - 5ms/epoch - 477us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.3859 - accuracy: 0.4384 - 5ms/epoch - 454us/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.3005 - accuracy: 0.4555 - 4ms/epoch - 437us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 1.2416 - accuracy: 0.4521 - 4ms/epoch - 438us/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 1.1630 - accuracy: 0.4726 - 5ms/epoch - 529us/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 1.1081 - accuracy: 0.5000 - 5ms/epoch - 485us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 1.0679 - accuracy: 0.5171 - 5ms/epoch - 480us/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 1.0312 - accuracy: 0.5205 - 6ms/epoch - 592us/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 1.0710 - accuracy: 0.4932 - 5ms/epoch - 539us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.9804 - accuracy: 0.6164 - 5ms/epoch - 529us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.9500 - accuracy: 0.5240 - 6ms/epoch - 572us/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.9217 - accuracy: 0.5822 - 5ms/epoch - 532us/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.9114 - accuracy: 0.5616 - 5ms/epoch - 528us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.8900 - accuracy: 0.6164 - 5ms/epoch - 541us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.8828 - accuracy: 0.6130 - 5ms/epoch - 516us/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.8690 - accuracy: 0.5993 - 5ms/epoch - 546us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.8852 - accuracy: 0.6233 - 5ms/epoch - 544us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.8506 - accuracy: 0.6301 - 5ms/epoch - 529us/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.8548 - accuracy: 0.6199 - 6ms/epoch - 574us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.8397 - accuracy: 0.6370 - 5ms/epoch - 529us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.8101 - accuracy: 0.6404 - 5ms/epoch - 518us/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.8264 - accuracy: 0.6027 - 6ms/epoch - 580us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.8358 - accuracy: 0.5993 - 5ms/epoch - 527us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.8151 - accuracy: 0.5993 - 5ms/epoch - 542us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.7945 - accuracy: 0.6438 - 6ms/epoch - 555us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.7724 - accuracy: 0.6610 - 5ms/epoch - 537us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.7768 - accuracy: 0.6438 - 10ms/epoch - 973us/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.7590 - accuracy: 0.6301 - 6ms/epoch - 642us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.7583 - accuracy: 0.6473 - 6ms/epoch - 623us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.7872 - accuracy: 0.6404 - 5ms/epoch - 526us/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.7683 - accuracy: 0.6575 - 5ms/epoch - 513us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.7742 - accuracy: 0.6473 - 6ms/epoch - 592us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.7502 - accuracy: 0.6507 - 5ms/epoch - 545us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.7314 - accuracy: 0.6747 - 6ms/epoch - 576us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.7228 - accuracy: 0.6815 - 6ms/epoch - 560us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.7299 - accuracy: 0.6815 - 5ms/epoch - 538us/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.7505 - accuracy: 0.6712 - 6ms/epoch - 569us/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.7447 - accuracy: 0.6644 - 5ms/epoch - 546us/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.7298 - accuracy: 0.6747 - 5ms/epoch - 528us/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.7204 - accuracy: 0.6644 - 6ms/epoch - 578us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.7086 - accuracy: 0.6781 - 5ms/epoch - 521us/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.7089 - accuracy: 0.6712 - 6ms/epoch - 565us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.6936 - accuracy: 0.6849 - 5ms/epoch - 524us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.6961 - accuracy: 0.6952 - 5ms/epoch - 514us/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.7056 - accuracy: 0.6747 - 6ms/epoch - 560us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.6825 - accuracy: 0.6952 - 5ms/epoch - 535us/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.6781 - accuracy: 0.6781 - 5ms/epoch - 537us/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.6647 - accuracy: 0.7158 - 6ms/epoch - 587us/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.6640 - accuracy: 0.6815 - 5ms/epoch - 524us/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.6684 - accuracy: 0.6781 - 5ms/epoch - 528us/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.7184 - accuracy: 0.6781 - 5ms/epoch - 543us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.6699 - accuracy: 0.6781 - 5ms/epoch - 535us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.6560 - accuracy: 0.7055 - 5ms/epoch - 548us/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.6592 - accuracy: 0.6815 - 5ms/epoch - 542us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.6524 - accuracy: 0.7123 - 5ms/epoch - 523us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.6668 - accuracy: 0.6884 - 6ms/epoch - 551us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.6312 - accuracy: 0.7466 - 5ms/epoch - 517us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.6221 - accuracy: 0.7329 - 5ms/epoch - 503us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.6451 - accuracy: 0.7192 - 6ms/epoch - 554us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.6246 - accuracy: 0.7363 - 5ms/epoch - 521us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.6153 - accuracy: 0.7295 - 5ms/epoch - 532us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.6190 - accuracy: 0.7500 - 5ms/epoch - 548us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.6756 - accuracy: 0.6986 - 5ms/epoch - 501us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.6380 - accuracy: 0.6986 - 5ms/epoch - 503us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.6406 - accuracy: 0.7123 - 5ms/epoch - 505us/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.7054 - accuracy: 0.6575 - 5ms/epoch - 518us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.6118 - accuracy: 0.7466 - 5ms/epoch - 521us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.6035 - accuracy: 0.7466 - 5ms/epoch - 497us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.5933 - accuracy: 0.7397 - 5ms/epoch - 522us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.5989 - accuracy: 0.7260 - 5ms/epoch - 537us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.5986 - accuracy: 0.7295 - 5ms/epoch - 508us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.5899 - accuracy: 0.7363 - 5ms/epoch - 505us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.5845 - accuracy: 0.7432 - 5ms/epoch - 520us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.5949 - accuracy: 0.7363 - 5ms/epoch - 539us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.5970 - accuracy: 0.7192 - 5ms/epoch - 530us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.5726 - accuracy: 0.7466 - 6ms/epoch - 557us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.5761 - accuracy: 0.7432 - 5ms/epoch - 532us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.5914 - accuracy: 0.7397 - 5ms/epoch - 530us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.6409 - accuracy: 0.6815 - 6ms/epoch - 551us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.6355 - accuracy: 0.7055 - 5ms/epoch - 530us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.6008 - accuracy: 0.7089 - 5ms/epoch - 526us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.6218 - accuracy: 0.7055 - 5ms/epoch - 545us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.6063 - accuracy: 0.6952 - 5ms/epoch - 515us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.6040 - accuracy: 0.7329 - 5ms/epoch - 541us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.6075 - accuracy: 0.6918 - 5ms/epoch - 525us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.5944 - accuracy: 0.7021 - 5ms/epoch - 544us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.5862 - accuracy: 0.7226 - 5ms/epoch - 541us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.5630 - accuracy: 0.7534 - 5ms/epoch - 501us/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.5527 - accuracy: 0.7466 - 5ms/epoch - 496us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.5890 - accuracy: 0.7260 - 5ms/epoch - 532us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.5500 - accuracy: 0.7568 - 5ms/epoch - 534us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.5359 - accuracy: 0.7637 - 5ms/epoch - 521us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.5337 - accuracy: 0.7774 - 5ms/epoch - 528us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.5220 - accuracy: 0.7774 - 5ms/epoch - 518us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.5251 - accuracy: 0.7911 - 5ms/epoch - 525us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.5469 - accuracy: 0.7637 - 6ms/epoch - 552us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.5275 - accuracy: 0.7534 - 5ms/epoch - 509us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.5176 - accuracy: 0.7705 - 5ms/epoch - 520us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.5309 - accuracy: 0.7637 - 6ms/epoch - 552us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.5105 - accuracy: 0.7911 - 5ms/epoch - 533us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.5180 - accuracy: 0.7637 - 5ms/epoch - 519us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.5393 - accuracy: 0.7534 - 5ms/epoch - 515us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.5163 - accuracy: 0.7637 - 5ms/epoch - 525us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.5031 - accuracy: 0.7808 - 6ms/epoch - 555us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.4895 - accuracy: 0.7877 - 5ms/epoch - 532us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.5050 - accuracy: 0.7705 - 5ms/epoch - 520us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.4974 - accuracy: 0.7808 - 5ms/epoch - 547us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.4884 - accuracy: 0.7740 - 5ms/epoch - 521us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.4938 - accuracy: 0.7774 - 5ms/epoch - 501us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.4806 - accuracy: 0.8014 - 6ms/epoch - 559us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.5063 - accuracy: 0.7671 - 5ms/epoch - 514us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.4997 - accuracy: 0.7740 - 5ms/epoch - 487us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.5369 - accuracy: 0.7705 - 5ms/epoch - 549us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.4856 - accuracy: 0.7774 - 5ms/epoch - 506us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.4764 - accuracy: 0.8048 - 5ms/epoch - 521us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.5334 - accuracy: 0.7637 - 5ms/epoch - 524us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.5148 - accuracy: 0.7534 - 5ms/epoch - 517us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.5472 - accuracy: 0.7329 - 5ms/epoch - 528us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.4931 - accuracy: 0.7842 - 5ms/epoch - 505us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.4949 - accuracy: 0.7842 - 5ms/epoch - 510us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.5271 - accuracy: 0.7637 - 5ms/epoch - 518us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.4844 - accuracy: 0.7945 - 5ms/epoch - 513us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.4720 - accuracy: 0.7842 - 5ms/epoch - 530us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.4765 - accuracy: 0.7740 - 5ms/epoch - 543us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.4837 - accuracy: 0.7808 - 5ms/epoch - 520us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.4495 - accuracy: 0.8219 - 5ms/epoch - 517us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.4604 - accuracy: 0.7842 - 5ms/epoch - 492us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.4370 - accuracy: 0.8185 - 5ms/epoch - 531us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.4574 - accuracy: 0.8082 - 5ms/epoch - 517us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.5075 - accuracy: 0.7911 - 5ms/epoch - 500us/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.5128 - accuracy: 0.7877 - 5ms/epoch - 524us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.4481 - accuracy: 0.8014 - 5ms/epoch - 517us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.4256 - accuracy: 0.8151 - 5ms/epoch - 526us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.4474 - accuracy: 0.8151 - 5ms/epoch - 504us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.4398 - accuracy: 0.7945 - 5ms/epoch - 516us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.4299 - accuracy: 0.8151 - 5ms/epoch - 499us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.4408 - accuracy: 0.8151 - 6ms/epoch - 550us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.4528 - accuracy: 0.7774 - 5ms/epoch - 518us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.4506 - accuracy: 0.8048 - 5ms/epoch - 527us/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.4401 - accuracy: 0.7979 - 5ms/epoch - 521us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.4192 - accuracy: 0.8116 - 5ms/epoch - 511us/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.4455 - accuracy: 0.7911 - 5ms/epoch - 515us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.4056 - accuracy: 0.8082 - 5ms/epoch - 542us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.4103 - accuracy: 0.8151 - 5ms/epoch - 492us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.4191 - accuracy: 0.8219 - 5ms/epoch - 533us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.4148 - accuracy: 0.8048 - 5ms/epoch - 507us/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.4128 - accuracy: 0.7979 - 5ms/epoch - 539us/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.4518 - accuracy: 0.7911 - 5ms/epoch - 515us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.4723 - accuracy: 0.7808 - 5ms/epoch - 511us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.5049 - accuracy: 0.7637 - 5ms/epoch - 499us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.4237 - accuracy: 0.8116 - 5ms/epoch - 533us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.4150 - accuracy: 0.8048 - 5ms/epoch - 518us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.4592 - accuracy: 0.7911 - 5ms/epoch - 530us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.4044 - accuracy: 0.8185 - 5ms/epoch - 517us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.4219 - accuracy: 0.7945 - 5ms/epoch - 519us/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.4033 - accuracy: 0.8185 - 5ms/epoch - 501us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.4007 - accuracy: 0.7979 - 5ms/epoch - 534us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.4048 - accuracy: 0.8185 - 5ms/epoch - 505us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.4306 - accuracy: 0.8219 - 5ms/epoch - 527us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.4056 - accuracy: 0.8390 - 5ms/epoch - 524us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.3740 - accuracy: 0.8322 - 5ms/epoch - 500us/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.3859 - accuracy: 0.8219 - 5ms/epoch - 524us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.4075 - accuracy: 0.8151 - 5ms/epoch - 514us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.3849 - accuracy: 0.8219 - 5ms/epoch - 520us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.3769 - accuracy: 0.8322 - 5ms/epoch - 524us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.3730 - accuracy: 0.8151 - 5ms/epoch - 515us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.3666 - accuracy: 0.8390 - 5ms/epoch - 527us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.3963 - accuracy: 0.8253 - 5ms/epoch - 538us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.3738 - accuracy: 0.8356 - 5ms/epoch - 525us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.3771 - accuracy: 0.8151 - 5ms/epoch - 519us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.3886 - accuracy: 0.8288 - 5ms/epoch - 538us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.4554 - accuracy: 0.7945 - 5ms/epoch - 532us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.4055 - accuracy: 0.8014 - 5ms/epoch - 529us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.3740 - accuracy: 0.8288 - 5ms/epoch - 514us/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.3709 - accuracy: 0.8288 - 5ms/epoch - 512us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.3585 - accuracy: 0.8425 - 5ms/epoch - 546us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.3945 - accuracy: 0.8151 - 5ms/epoch - 495us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.3762 - accuracy: 0.8253 - 5ms/epoch - 529us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.3859 - accuracy: 0.8459 - 6ms/epoch - 554us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.3829 - accuracy: 0.8253 - 5ms/epoch - 520us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.3655 - accuracy: 0.8322 - 5ms/epoch - 517us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.3598 - accuracy: 0.8219 - 5ms/epoch - 533us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.3791 - accuracy: 0.8356 - 5ms/epoch - 513us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.3602 - accuracy: 0.8390 - 5ms/epoch - 503us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.3505 - accuracy: 0.8459 - 5ms/epoch - 525us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.4086 - accuracy: 0.8219 - 5ms/epoch - 493us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.3798 - accuracy: 0.8288 - 5ms/epoch - 515us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.3495 - accuracy: 0.8596 - 5ms/epoch - 541us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.3466 - accuracy: 0.8390 - 5ms/epoch - 535us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.3496 - accuracy: 0.8664 - 5ms/epoch - 546us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.3976 - accuracy: 0.8014 - 5ms/epoch - 511us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.3457 - accuracy: 0.8356 - 5ms/epoch - 517us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.3624 - accuracy: 0.8288 - 5ms/epoch - 520us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.3388 - accuracy: 0.8527 - 5ms/epoch - 519us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.3559 - accuracy: 0.8390 - 5ms/epoch - 527us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.3381 - accuracy: 0.8288 - 6ms/epoch - 581us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.3890 - accuracy: 0.8116 - 5ms/epoch - 528us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.3410 - accuracy: 0.8562 - 5ms/epoch - 520us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x169fa1240>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cddb8015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.6954 - accuracy: 0.7653 - 41ms/epoch - 10ms/step\n",
      "Loss: 0.695381224155426, Accuracy: 0.7653061151504517\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06451517",
   "metadata": {},
   "source": [
    "# CRE Loan Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "974fa4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observation_date', 'CRE_CO', 'CRE_DELNQ', 'Rental_Vacancy_Rate', 'GDP',\n",
       "       'CORP_DEBT_NET_WORTH', 'Manufacturing_Confidence', 'FEDFUNDS',\n",
       "       'CORP_SAVINGS_LEVEL', 'UNRATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create CRE loan dataset\n",
    "CRE_df = main_df[['observation_date', 'CRE_CO', 'CRE_DELNQ', 'Rental_Vacancy_Rate', 'GDP', 'CORP_DEBT_NET_WORTH', 'Manufacturing_Confidence', 'FEDFUNDS', 'CORP_SAVINGS_LEVEL', 'UNRATE']]\n",
    "\n",
    "CRE_bin_df = mort_df.copy()\n",
    "\n",
    "CRE_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb8ab125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRE_DELNQ</th>\n",
       "      <th>Rental_Vacancy_Rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>CORP_DEBT_NET_WORTH</th>\n",
       "      <th>Manufacturing_Confidence</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>CORP_SAVINGS_LEVEL</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.08</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>96.951745</td>\n",
       "      <td>6.91</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.08</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>96.972896</td>\n",
       "      <td>6.25</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.08</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>46.132964</td>\n",
       "      <td>97.223425</td>\n",
       "      <td>6.12</td>\n",
       "      <td>77.964</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.82</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>46.289579</td>\n",
       "      <td>97.678049</td>\n",
       "      <td>5.91</td>\n",
       "      <td>81.294</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.82</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>46.289579</td>\n",
       "      <td>98.292261</td>\n",
       "      <td>5.78</td>\n",
       "      <td>81.294</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.77</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.497128</td>\n",
       "      <td>98.951152</td>\n",
       "      <td>4.57</td>\n",
       "      <td>263.194</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.77</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.497128</td>\n",
       "      <td>98.913862</td>\n",
       "      <td>4.65</td>\n",
       "      <td>263.194</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.84</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.904602</td>\n",
       "      <td>4.83</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.84</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.887364</td>\n",
       "      <td>5.06</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.84</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>39.659559</td>\n",
       "      <td>98.872005</td>\n",
       "      <td>5.08</td>\n",
       "      <td>367.036</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRE_DELNQ  Rental_Vacancy_Rate  GDP  CORP_DEBT_NET_WORTH  \\\n",
       "0        12.08                  7.5 -1.9            46.132964   \n",
       "1        12.08                  7.5 -1.9            46.132964   \n",
       "2        12.08                  7.5 -1.9            46.132964   \n",
       "3        11.82                  7.3  3.2            46.289579   \n",
       "4        11.82                  7.3  3.2            46.289579   \n",
       "..         ...                  ...  ...                  ...   \n",
       "385       0.77                  6.4  2.2            40.497128   \n",
       "386       0.77                  6.4  2.2            40.497128   \n",
       "387       0.84                  6.3  2.1            39.659559   \n",
       "388       0.84                  6.3  2.1            39.659559   \n",
       "389       0.84                  6.3  2.1            39.659559   \n",
       "\n",
       "     Manufacturing_Confidence  FEDFUNDS  CORP_SAVINGS_LEVEL  UNRATE  \n",
       "0                   96.951745      6.91              77.964     6.4  \n",
       "1                   96.972896      6.25              77.964     6.6  \n",
       "2                   97.223425      6.12              77.964     6.8  \n",
       "3                   97.678049      5.91              81.294     6.7  \n",
       "4                   98.292261      5.78              81.294     6.9  \n",
       "..                        ...       ...                 ...     ...  \n",
       "385                 98.951152      4.57             263.194     3.6  \n",
       "386                 98.913862      4.65             263.194     3.5  \n",
       "387                 98.904602      4.83             367.036     3.4  \n",
       "388                 98.887364      5.06             367.036     3.7  \n",
       "389                 98.872005      5.08             367.036     3.6  \n",
       "\n",
       "[390 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binning the data for classification Question: \n",
    "CRE_bin_df[\"CRE_CO_BIN\"] = pd.qcut(CRE_df['CRE_CO'],4, labels= [1, 2, 3, 4])\n",
    "\n",
    "# Define the dependent Y variable\n",
    "y = CRE_bin_df[\"CRE_CO_BIN\"]\n",
    "\n",
    "CRE_df = CRE_df.drop(columns=['CRE_CO','observation_date'])\n",
    "CRE_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90154201",
   "metadata": {},
   "source": [
    "# Machine Learning: CRE Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d27e48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ccard_df, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01b8ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75c3879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set shape:  (292, 7)\n",
      "y_train set shape:  (292,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train set shape: \", X_train_scaled.shape)\n",
    "print(\"y_train set shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fb2cc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 2, 3, ..., 2, 1, 1, 4, 3]\n",
       "Length: 292\n",
       "Categories (4, int64): [1 < 2 < 3 < 4]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "354ee1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "y_train = to_categorical(y_train.values, num_classes)\n",
    "y_test = to_categorical(y_test.values, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "808337ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 205       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11385 (44.47 KB)\n",
      "Trainable params: 11385 (44.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "number_input_features = X_train_scaled.shape[1]\n",
    "hidden_nodes_layers1 = 60\n",
    "hidden_nodes_layers2 = 60\n",
    "hidden_nodes_layers3 = 60\n",
    "hidden_nodes_layers4 = 40\n",
    "\n",
    "\n",
    "model.add(Dense(20, activation='relu', input_dim=number_input_features))\n",
    "model.add(Dense(hidden_nodes_layers1, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers2, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers3, activation='relu'))\n",
    "model.add(Dense(hidden_nodes_layers4, activation='relu'))\n",
    "# model.add(Dense(hidden_nodes_layers5, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "359fae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 1.5768 - accuracy: 0.2329 - 126ms/epoch - 13ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 1.5112 - accuracy: 0.2329 - 5ms/epoch - 521us/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 1.4450 - accuracy: 0.2329 - 5ms/epoch - 509us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 1.3639 - accuracy: 0.2877 - 5ms/epoch - 469us/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 1.2727 - accuracy: 0.3699 - 5ms/epoch - 499us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 1.1605 - accuracy: 0.5479 - 5ms/epoch - 458us/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 1.0419 - accuracy: 0.6096 - 6ms/epoch - 565us/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 0.9444 - accuracy: 0.6747 - 5ms/epoch - 471us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 0.8654 - accuracy: 0.6918 - 5ms/epoch - 486us/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.8330 - accuracy: 0.6781 - 5ms/epoch - 540us/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.7464 - accuracy: 0.7192 - 5ms/epoch - 524us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.7169 - accuracy: 0.7192 - 6ms/epoch - 552us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.6895 - accuracy: 0.7534 - 6ms/epoch - 576us/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.6572 - accuracy: 0.7432 - 5ms/epoch - 520us/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.6847 - accuracy: 0.7158 - 6ms/epoch - 569us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.6074 - accuracy: 0.7603 - 5ms/epoch - 542us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.5831 - accuracy: 0.7637 - 5ms/epoch - 514us/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.5757 - accuracy: 0.7842 - 6ms/epoch - 578us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.5326 - accuracy: 0.8082 - 5ms/epoch - 530us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.5232 - accuracy: 0.8185 - 5ms/epoch - 520us/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.4966 - accuracy: 0.8390 - 5ms/epoch - 549us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.4805 - accuracy: 0.8253 - 5ms/epoch - 531us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.5270 - accuracy: 0.7808 - 6ms/epoch - 567us/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.4850 - accuracy: 0.8048 - 6ms/epoch - 555us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.4725 - accuracy: 0.8151 - 5ms/epoch - 524us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.4509 - accuracy: 0.8185 - 6ms/epoch - 609us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.4450 - accuracy: 0.8151 - 5ms/epoch - 547us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.4753 - accuracy: 0.7945 - 5ms/epoch - 520us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.4272 - accuracy: 0.8356 - 6ms/epoch - 584us/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.3999 - accuracy: 0.8562 - 5ms/epoch - 539us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.4047 - accuracy: 0.8493 - 5ms/epoch - 519us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.3988 - accuracy: 0.8493 - 6ms/epoch - 556us/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.4222 - accuracy: 0.8288 - 5ms/epoch - 533us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.4067 - accuracy: 0.8459 - 5ms/epoch - 542us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.3975 - accuracy: 0.8630 - 5ms/epoch - 540us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.4446 - accuracy: 0.8048 - 5ms/epoch - 529us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.3788 - accuracy: 0.8630 - 6ms/epoch - 590us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.3812 - accuracy: 0.8630 - 5ms/epoch - 534us/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.3701 - accuracy: 0.8699 - 5ms/epoch - 516us/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.3670 - accuracy: 0.8630 - 6ms/epoch - 618us/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.3804 - accuracy: 0.8630 - 5ms/epoch - 523us/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.3516 - accuracy: 0.8767 - 6ms/epoch - 584us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.3290 - accuracy: 0.8904 - 5ms/epoch - 532us/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.3327 - accuracy: 0.8836 - 6ms/epoch - 552us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.3259 - accuracy: 0.8801 - 6ms/epoch - 619us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.3684 - accuracy: 0.8596 - 5ms/epoch - 538us/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.3455 - accuracy: 0.8459 - 5ms/epoch - 531us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.3265 - accuracy: 0.8767 - 6ms/epoch - 584us/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.3714 - accuracy: 0.8459 - 5ms/epoch - 535us/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.3361 - accuracy: 0.8801 - 6ms/epoch - 557us/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.3139 - accuracy: 0.8870 - 6ms/epoch - 568us/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.2971 - accuracy: 0.8904 - 5ms/epoch - 524us/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.3315 - accuracy: 0.8699 - 5ms/epoch - 548us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.3142 - accuracy: 0.8904 - 5ms/epoch - 543us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.2974 - accuracy: 0.8836 - 5ms/epoch - 509us/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.2922 - accuracy: 0.8836 - 6ms/epoch - 589us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.2927 - accuracy: 0.9007 - 5ms/epoch - 539us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.2818 - accuracy: 0.8836 - 5ms/epoch - 505us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.3087 - accuracy: 0.8870 - 6ms/epoch - 608us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.2794 - accuracy: 0.9041 - 5ms/epoch - 530us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.2688 - accuracy: 0.9041 - 5ms/epoch - 517us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.2642 - accuracy: 0.9075 - 5ms/epoch - 548us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.2919 - accuracy: 0.8870 - 5ms/epoch - 535us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.2887 - accuracy: 0.9075 - 5ms/epoch - 529us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.2690 - accuracy: 0.9041 - 5ms/epoch - 515us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.2622 - accuracy: 0.9007 - 5ms/epoch - 519us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.3061 - accuracy: 0.8904 - 5ms/epoch - 513us/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.2632 - accuracy: 0.9007 - 5ms/epoch - 532us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.2862 - accuracy: 0.8801 - 5ms/epoch - 505us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.3227 - accuracy: 0.8699 - 5ms/epoch - 496us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.2747 - accuracy: 0.8767 - 5ms/epoch - 543us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.2675 - accuracy: 0.8801 - 5ms/epoch - 514us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.2588 - accuracy: 0.8801 - 5ms/epoch - 540us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.3339 - accuracy: 0.8459 - 5ms/epoch - 529us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.2912 - accuracy: 0.8801 - 5ms/epoch - 511us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.2621 - accuracy: 0.8801 - 5ms/epoch - 487us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.2564 - accuracy: 0.8904 - 5ms/epoch - 543us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.3899 - accuracy: 0.8596 - 5ms/epoch - 528us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.2801 - accuracy: 0.8562 - 5ms/epoch - 511us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.2579 - accuracy: 0.9075 - 5ms/epoch - 518us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.2477 - accuracy: 0.9007 - 5ms/epoch - 513us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.2509 - accuracy: 0.9075 - 5ms/epoch - 505us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.2403 - accuracy: 0.9144 - 5ms/epoch - 503us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.2190 - accuracy: 0.9075 - 5ms/epoch - 524us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.2271 - accuracy: 0.9144 - 5ms/epoch - 545us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.2176 - accuracy: 0.9075 - 5ms/epoch - 515us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.2895 - accuracy: 0.9041 - 5ms/epoch - 543us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.2526 - accuracy: 0.9007 - 5ms/epoch - 538us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.2397 - accuracy: 0.9110 - 5ms/epoch - 507us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.2141 - accuracy: 0.9178 - 6ms/epoch - 555us/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.2176 - accuracy: 0.9212 - 5ms/epoch - 529us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.2222 - accuracy: 0.9144 - 5ms/epoch - 519us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.2503 - accuracy: 0.8973 - 5ms/epoch - 504us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.2070 - accuracy: 0.9247 - 5ms/epoch - 524us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.1965 - accuracy: 0.9110 - 5ms/epoch - 503us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.2155 - accuracy: 0.9349 - 5ms/epoch - 498us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.2466 - accuracy: 0.9007 - 5ms/epoch - 519us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.2111 - accuracy: 0.9144 - 5ms/epoch - 512us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.2003 - accuracy: 0.9315 - 5ms/epoch - 526us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.2460 - accuracy: 0.8938 - 5ms/epoch - 518us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.2466 - accuracy: 0.9144 - 5ms/epoch - 510us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.2171 - accuracy: 0.9110 - 5ms/epoch - 524us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.2027 - accuracy: 0.9349 - 5ms/epoch - 533us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.2034 - accuracy: 0.9144 - 5ms/epoch - 517us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.1973 - accuracy: 0.9418 - 5ms/epoch - 522us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.1873 - accuracy: 0.9349 - 5ms/epoch - 507us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.1809 - accuracy: 0.9384 - 5ms/epoch - 507us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.1781 - accuracy: 0.9247 - 5ms/epoch - 518us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.1839 - accuracy: 0.9212 - 5ms/epoch - 517us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.1852 - accuracy: 0.9315 - 5ms/epoch - 520us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.1866 - accuracy: 0.9384 - 5ms/epoch - 518us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.1948 - accuracy: 0.9144 - 5ms/epoch - 508us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.1995 - accuracy: 0.9212 - 5ms/epoch - 535us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.2426 - accuracy: 0.9178 - 5ms/epoch - 507us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.2497 - accuracy: 0.9075 - 5ms/epoch - 514us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.2054 - accuracy: 0.9247 - 5ms/epoch - 506us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.2408 - accuracy: 0.9110 - 5ms/epoch - 534us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.1758 - accuracy: 0.9452 - 5ms/epoch - 533us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.1944 - accuracy: 0.9178 - 5ms/epoch - 528us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.1968 - accuracy: 0.9349 - 5ms/epoch - 519us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.2447 - accuracy: 0.8904 - 5ms/epoch - 506us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.2467 - accuracy: 0.9144 - 5ms/epoch - 507us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.2080 - accuracy: 0.9144 - 5ms/epoch - 506us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.1874 - accuracy: 0.9212 - 5ms/epoch - 516us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.1832 - accuracy: 0.9281 - 5ms/epoch - 532us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.1666 - accuracy: 0.9349 - 5ms/epoch - 519us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.1689 - accuracy: 0.9452 - 5ms/epoch - 501us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.1848 - accuracy: 0.9247 - 5ms/epoch - 511us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.1917 - accuracy: 0.9349 - 5ms/epoch - 515us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.1800 - accuracy: 0.9384 - 5ms/epoch - 510us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.1588 - accuracy: 0.9349 - 5ms/epoch - 540us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.1604 - accuracy: 0.9384 - 5ms/epoch - 527us/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.1797 - accuracy: 0.9281 - 5ms/epoch - 514us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.1614 - accuracy: 0.9452 - 5ms/epoch - 539us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.1539 - accuracy: 0.9452 - 5ms/epoch - 521us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.1600 - accuracy: 0.9452 - 5ms/epoch - 528us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.1568 - accuracy: 0.9315 - 5ms/epoch - 522us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.1608 - accuracy: 0.9281 - 5ms/epoch - 516us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.1589 - accuracy: 0.9384 - 5ms/epoch - 544us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.1871 - accuracy: 0.9178 - 5ms/epoch - 503us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.1577 - accuracy: 0.9315 - 5ms/epoch - 522us/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.1587 - accuracy: 0.9418 - 5ms/epoch - 503us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.1536 - accuracy: 0.9315 - 5ms/epoch - 530us/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.1550 - accuracy: 0.9521 - 5ms/epoch - 522us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 0.1770 - accuracy: 0.9247 - 6ms/epoch - 552us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 0.2136 - accuracy: 0.9178 - 5ms/epoch - 516us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 0.1761 - accuracy: 0.9349 - 6ms/epoch - 585us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 0.1860 - accuracy: 0.9110 - 5ms/epoch - 506us/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 0.1819 - accuracy: 0.9315 - 5ms/epoch - 536us/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 0.1496 - accuracy: 0.9349 - 5ms/epoch - 541us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 0.1465 - accuracy: 0.9452 - 5ms/epoch - 519us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 0.1428 - accuracy: 0.9418 - 5ms/epoch - 517us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 0.1571 - accuracy: 0.9349 - 5ms/epoch - 498us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 0.1405 - accuracy: 0.9418 - 9ms/epoch - 918us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 0.1461 - accuracy: 0.9315 - 6ms/epoch - 578us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 0.1831 - accuracy: 0.9075 - 6ms/epoch - 550us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 0.1643 - accuracy: 0.9315 - 5ms/epoch - 535us/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 0.1474 - accuracy: 0.9349 - 5ms/epoch - 543us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 0.1471 - accuracy: 0.9486 - 5ms/epoch - 524us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 0.1701 - accuracy: 0.9349 - 5ms/epoch - 520us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 0.1687 - accuracy: 0.9315 - 5ms/epoch - 543us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 0.1537 - accuracy: 0.9247 - 5ms/epoch - 529us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 0.1466 - accuracy: 0.9486 - 5ms/epoch - 531us/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 0.1353 - accuracy: 0.9452 - 5ms/epoch - 540us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 0.1465 - accuracy: 0.9452 - 5ms/epoch - 527us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 0.1383 - accuracy: 0.9486 - 5ms/epoch - 515us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 0.1364 - accuracy: 0.9384 - 5ms/epoch - 541us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 0.1491 - accuracy: 0.9418 - 5ms/epoch - 502us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 0.1968 - accuracy: 0.9110 - 5ms/epoch - 498us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 0.1847 - accuracy: 0.9418 - 5ms/epoch - 546us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 0.1513 - accuracy: 0.9384 - 5ms/epoch - 508us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 0.1530 - accuracy: 0.9384 - 5ms/epoch - 503us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 0.1406 - accuracy: 0.9315 - 5ms/epoch - 535us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 0.1281 - accuracy: 0.9521 - 5ms/epoch - 531us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 0.1283 - accuracy: 0.9452 - 5ms/epoch - 550us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 0.1448 - accuracy: 0.9349 - 5ms/epoch - 524us/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 0.1501 - accuracy: 0.9315 - 5ms/epoch - 530us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 0.1367 - accuracy: 0.9384 - 5ms/epoch - 543us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 0.1362 - accuracy: 0.9452 - 5ms/epoch - 519us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 0.1886 - accuracy: 0.9212 - 5ms/epoch - 543us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 0.2072 - accuracy: 0.9281 - 6ms/epoch - 563us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 0.2419 - accuracy: 0.8904 - 5ms/epoch - 518us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 0.1761 - accuracy: 0.9452 - 5ms/epoch - 514us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 0.1938 - accuracy: 0.9075 - 5ms/epoch - 519us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 0.2451 - accuracy: 0.9144 - 5ms/epoch - 516us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 0.1594 - accuracy: 0.9349 - 5ms/epoch - 527us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 0.1583 - accuracy: 0.9349 - 5ms/epoch - 536us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 0.1287 - accuracy: 0.9486 - 5ms/epoch - 513us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 0.1212 - accuracy: 0.9486 - 5ms/epoch - 503us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 0.1230 - accuracy: 0.9418 - 5ms/epoch - 512us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 0.1265 - accuracy: 0.9486 - 5ms/epoch - 523us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 0.1372 - accuracy: 0.9315 - 5ms/epoch - 530us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 0.1189 - accuracy: 0.9555 - 5ms/epoch - 518us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 0.1324 - accuracy: 0.9486 - 5ms/epoch - 521us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 0.1431 - accuracy: 0.9349 - 5ms/epoch - 503us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 0.1409 - accuracy: 0.9384 - 5ms/epoch - 543us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 0.1337 - accuracy: 0.9452 - 5ms/epoch - 505us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 0.2905 - accuracy: 0.8973 - 5ms/epoch - 535us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 0.2075 - accuracy: 0.9144 - 5ms/epoch - 508us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 0.2884 - accuracy: 0.8904 - 5ms/epoch - 504us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x283ae79a0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a63aa239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.4286 - accuracy: 0.8367 - 40ms/epoch - 10ms/step\n",
      "Loss: 0.4286101460456848, Accuracy: 0.8367347121238708\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c354761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
